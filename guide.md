# H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng D·ª± √Ån Roll Rate Model - Calibration

## üìã T·ªïng Quan D·ª± √Ån

D·ª± √°n **Roll Rate Model** l√† m·ªôt h·ªá th·ªëng d·ª± b√°o r·ªßi ro t√≠n d·ª•ng d·ª±a tr√™n **Markov Chain**, cho ph√©p:
- T√≠nh to√°n ma tr·∫≠n chuy·ªÉn tr·∫°ng th√°i DPD (Days Past Due)
- D·ª± b√°o ph√¢n ph·ªëi r·ªßi ro 12-36 th√°ng t·ªõi
- **Calibration** ƒë·ªÉ ƒëi·ªÅu ch·ªânh d·ª± b√°o s√°t v·ªõi th·ª±c t·∫ø
- Backtest v√† validation

---

## üéØ Ph·∫ßn CALIBRATION - Tr·ªçng T√¢m

### 1. Calibration L√† G√¨?

**Calibration** l√† qu√° tr√¨nh ƒëi·ªÅu ch·ªânh d·ª± b√°o t·ª´ m√¥ h√¨nh Markov ƒë·ªÉ kh·ªõp v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø. M√¥ h√¨nh Markov thu·∫ßn t√∫y c√≥ th·ªÉ:
- D·ª± b√°o qu√° cao ho·∫∑c qu√° th·∫•p
- Kh√¥ng ph·∫£n √°nh ƒë√∫ng xu h∆∞·ªõng th·ªã tr∆∞·ªùng hi·ªán t·∫°i
- Thi·∫øu t√≠nh m√πa v·ª• (seasonality)

### 2. C√°c Ph∆∞∆°ng Ph√°p Calibration

D·ª± √°n cung c·∫•p **3 ph∆∞∆°ng ph√°p calibration** ch√≠nh:

#### **A. Calibration Per Product (calibration.py)**

**M·ª•c ƒë√≠ch:** ƒêi·ªÅu ch·ªânh theo t·ª´ng s·∫£n ph·∫©m v·ªõi h·ªá s·ªë k c·ªë ƒë·ªãnh

**C√¥ng th·ª©c:**
```
k_product = DEL90_actual / DEL90_forecast
DEL90_adjusted = DEL90_raw √ó k_product
```

**Khi n√†o d√πng:**
- Khi mu·ªën ƒëi·ªÅu ch·ªânh ƒë∆°n gi·∫£n, nhanh ch√≥ng
- Khi c√°c s·∫£n ph·∫©m c√≥ ƒë·∫∑c ƒëi·ªÉm r·ªßi ro kh√°c bi·ªát r√µ r·ªát

**File:** `src/rollrate/calibration.py`

**C√°c h√†m ch√≠nh:**
```python
# T√≠nh k per product
k_dict = compute_k_per_product_ifrs_fullhistory(
    df_actual=df_actual,
    df_forecast=df_forecast,
    H_map={"CDLPIL": 12, "TWLPIL": 12},  # MOB anchor
    method="trimmed_mean",  # ho·∫∑c "median"
    clip_min=0.3,
    clip_max=3.0
)

# √Åp d·ª•ng k v√†o lifecycle
df_calibrated = apply_k_to_lifecycle(
    df_lifecycle=df_lifecycle,
    k_dict=k_dict,
    m_apply_map={"CDLPIL": 4},  # B·∫Øt ƒë·∫ßu √°p k t·ª´ MOB 4
    blend_n=2  # Blend 2 k·ª≥ ƒë·∫ßu
)
```

**Tham s·ªë quan tr·ªçng:**
- `H_map`: MOB anchor ƒë·ªÉ t√≠nh k (th∆∞·ªùng 12 ho·∫∑c 24)
- `m_apply`: MOB b·∫Øt ƒë·∫ßu √°p d·ª•ng k (th∆∞·ªùng 4)
- `blend_n`: S·ªë k·ª≥ blend ƒë·ªÉ tr√°nh nh·∫£y ƒë·ªôt ng·ªôt
- `clip_min/max`: Gi·ªõi h·∫°n k ƒë·ªÉ tr√°nh outlier

---

#### **B. Calibration Per Product + Seasonality (calibration2.py)**

**M·ª•c ƒë√≠ch:** K·∫øt h·ª£p ƒëi·ªÅu ch·ªânh theo s·∫£n ph·∫©m V√Ä theo th√°ng gi·∫£i ng√¢n

**C√¥ng th·ª©c:**
```
k_product = mean(Actual @ MOB=H) / mean(Model @ MOB=H)
F_month = mean(Loss_month) / mean(Loss_all)
DEL_adjusted = DEL_raw √ó k_product √ó F_month
```

**Khi n√†o d√πng:**
- Khi c√≥ hi·ªán t∆∞·ª£ng m√πa v·ª• r√µ r·ªát (v√≠ d·ª•: T·∫øt, cu·ªëi nƒÉm)
- Khi mu·ªën tƒÉng ƒë·ªô ch√≠nh x√°c cho t·ª´ng cohort

**File:** `src/rollrate/calibration2.py`

**Workflow:**
```python
# B∆∞·ªõc 1: Build lifecycle actual only
df_actual = build_actual_lifecycle_amount_only(df_raw)

# B∆∞·ªõc 2: Build lifecycle model only (forecast)
df_model = build_model_lifecycle_amount_only(
    df_raw=df_raw,
    matrices_by_mob=matrices_by_mob,
    max_mob=29
)

# B∆∞·ªõc 3: T√≠nh k per product
k_dict = compute_k_per_product_auto(
    df_actual=df_actual,
    df_model=df_model,
    horizon_mob=12,
    metric_col="DEL90_PCT"
)

# B∆∞·ªõc 4: T√≠nh seasonality factor
month_factor = compute_month_seasonality(
    df_actual=df_actual,
    horizon_mob=12,
    metric_col="DEL90_PCT",
    min_cohort=5
)

# B∆∞·ªõc 5: √Åp d·ª•ng c·∫£ 2 layer
df_calibrated = apply_product_calibration(df_lifecycle, k_dict)
df_calibrated = apply_month_seasonality(df_calibrated, month_factor)
```

---

#### **C. Calibration Per MOB - WLS Method (calibration_kmob.py)** ‚≠ê **N√ÇNG CAO**

**M·ª•c ƒë√≠ch:** ƒêi·ªÅu ch·ªânh chi ti·∫øt theo t·ª´ng MOB v·ªõi ph∆∞∆°ng ph√°p Weighted Least Squares

**ƒê·∫∑c ƒëi·ªÉm:**
- H·ªá s·ªë k kh√°c nhau cho m·ªói MOB
- S·ª≠ d·ª•ng WLS ƒë·ªÉ fit k t·ª´ one-step forecast
- Smoothing ƒë·ªÉ tr√°nh k nh·∫£y ƒë·ªôt ng·ªôt
- Optional alpha scaling ƒë·ªÉ fit long-horizon target

**File:** `src/rollrate/calibration_kmob.py`

**Workflow ƒë·∫ßy ƒë·ªß:**

```python
# ===== B∆Ø·ªöC 1: Chu·∫©n b·ªã d·ªØ li·ªáu =====
states = BUCKETS_CANON
s30_states = BUCKETS_30P

# Actual lifecycle (history)
actual_results = get_actual_all_vintages_amount(df_raw)

# DISB_TOTAL map (cohort-based)
loan_disb = df_raw.groupby(
    ["PRODUCT_TYPE", "RISK_SCORE", "DISBURSAL_DATE", "AGREEMENT_ID"]
)["DISBURSAL_AMOUNT"].first()

cohort_disb = loan_disb.groupby(level=[0, 1, 2]).sum()
disb_total_by_vintage = cohort_disb.to_dict()

# ===== B∆Ø·ªöC 2: Fit k_raw theo MOB =====
k_raw_by_mob, weight_by_mob, k_raw_df = fit_k_raw(
    actual_results=actual_results,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    states=states,
    s30_states=s30_states,
    include_co=True,
    
    # Ch·ªçn ph∆∞∆°ng ph√°p
    method="wls",  # "wls", "wls_reg", ho·∫∑c "ratio"
    
    # WLS parameters
    eps=1e-8,
    min_denom=1e-10,
    min_obs=5,
    fallback_k=1.0,
    
    # Denominator mode
    denom_mode="disb",  # "disb" ho·∫∑c "ead"
    disb_total_by_vintage=disb_total_by_vintage,
    min_disb=1e-10,
    
    # Weight mode
    weight_mode="equal",  # "equal" ho·∫∑c "ead"
    
    return_detail=True
)

# ===== B∆Ø·ªöC 3: Smooth k curve =====
mob_min = min(k_raw_by_mob.keys())
mob_max = max(k_raw_by_mob.keys())

k_smooth_by_mob, mobs, k_vals = smooth_k(
    k_raw_by_mob=k_raw_by_mob,
    weight_by_mob=weight_by_mob,
    mob_min=mob_min,
    mob_max=mob_max,
    gamma=10.0,        # Penalty cho second-difference
    monotone=False,    # True n·∫øu mu·ªën k tƒÉng d·∫ßn
    use_cvxpy=True,    # D√πng CVXPY n·∫øu c√≥
    default_k=1.0
)

# ===== B∆Ø·ªöC 4: Fit alpha (optional) =====
alpha, k_final_by_mob, alpha_scores = fit_alpha(
    actual_results=actual_results,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    states=states,
    s30_states=s30_states,
    k_smooth_by_mob=k_smooth_by_mob,
    mob_target=24,     # MOB target ƒë·ªÉ fit alpha
    include_co=True,
    alpha_grid=None,   # M·∫∑c ƒë·ªãnh: np.arange(0.5, 1.5, 0.01)
    val_frac=0.2       # 20% vintages g·∫ßn nh·∫•t l√†m validation
)

# ===== B∆Ø·ªöC 5: Forecast v·ªõi k_final =====
forecast_results_calibrated = forecast_all_vintages_partial_step(
    actual_results=actual_results,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    max_mob=36,
    k_by_mob=k_final_by_mob,
    states=states
)

# ===== B∆Ø·ªöC 6: Backtest =====
backtest_df = backtest_error_by_mob(
    actual_results=actual_results,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    states=states,
    s30_states=s30_states,
    k_by_mob=k_final_by_mob,
    denom_mode="disb",
    disb_total_by_vintage=disb_total_by_vintage
)
```

**Gi·∫£i th√≠ch c√°c tham s·ªë:**

| Tham s·ªë | √ù nghƒ©a | Gi√° tr·ªã ƒë·ªÅ xu·∫•t |
|---------|---------|-----------------|
| `method` | Ph∆∞∆°ng ph√°p fit k | `"wls"` (chu·∫©n), `"wls_reg"` (c√≥ regularization), `"ratio"` (legacy) |
| `denom_mode` | M·∫´u s·ªë t√≠nh DEL | `"disb"` (chu·∫©n IFRS9), `"ead"` (theo EAD) |
| `weight_mode` | Tr·ªçng s·ªë vintages | `"equal"` (m·ªói vintage = 1), `"ead"` (theo EAD) |
| `gamma` | Penalty smoothing | 10.0 (c√†ng cao c√†ng smooth) |
| `monotone` | √âp k tƒÉng d·∫ßn | `False` (th∆∞·ªùng kh√¥ng c·∫ßn) |
| `alpha_grid` | Grid search alpha | `None` (auto: 0.5‚Üí1.5) |
| `val_frac` | T·ª∑ l·ªá validation | 0.2 (20% vintages g·∫ßn nh·∫•t) |

---

### 3. So S√°nh C√°c Ph∆∞∆°ng Ph√°p

| Ti√™u ch√≠ | Per Product | + Seasonality | Per MOB (WLS) |
|----------|-------------|---------------|---------------|
| **ƒê·ªô ph·ª©c t·∫°p** | ‚≠ê ƒê∆°n gi·∫£n | ‚≠ê‚≠ê Trung b√¨nh | ‚≠ê‚≠ê‚≠ê N√¢ng cao |
| **ƒê·ªô ch√≠nh x√°c** | Trung b√¨nh | Cao | R·∫•t cao |
| **Th·ªùi gian ch·∫°y** | Nhanh | Trung b√¨nh | Ch·∫≠m h∆°n |
| **Y√™u c·∫ßu data** | √çt | Trung b√¨nh | Nhi·ªÅu |
| **Khi n√†o d√πng** | Quick check | Production | Research/Fine-tuning |

---

### 4. L·ª±a Ch·ªçn Ph∆∞∆°ng Ph√°p Calibration

**D√πng Per Product khi:**
- C·∫ßn k·∫øt qu·∫£ nhanh
- Data √≠t (< 12 th√°ng)
- Ch·ªâ quan t√¢m trend t·ªïng th·ªÉ

**D√πng + Seasonality khi:**
- C√≥ hi·ªán t∆∞·ª£ng m√πa v·ª• r√µ
- Data ƒë·ªß (> 24 th√°ng)
- C·∫ßn ƒë·ªô ch√≠nh x√°c cao h∆°n

**D√πng Per MOB (WLS) khi:**
- C·∫ßn ƒë·ªô ch√≠nh x√°c t·ªëi ƒëa
- Data nhi·ªÅu (> 36 th√°ng)
- C√≥ th·ªùi gian ƒë·ªÉ tune parameters
- C·∫ßn gi·∫£i th√≠ch chi ti·∫øt cho regulator

---

### 5. Ki·ªÉm Tra K·∫øt Qu·∫£ Calibration

```python
# Visualize k curves
plot_k_curves(k_raw_by_mob, k_smooth_by_mob, k_final_by_mob)

# Backtest error by MOB
backtest_df = backtest_error_by_mob(...)
print(backtest_df.groupby("mob")[["mae_adj", "mae_mkv"]].mean())

# So s√°nh actual vs adjusted vs markov
forecast_vintage(
    actual_results=actual_results,
    matrices_by_mob=matrices_by_mob,
    vintage_key=("CDLPIL", "A", pd.Timestamp("2023-01-01")),
    states=states,
    s30_states=s30_states,
    k_by_mob=k_final_by_mob,
    mob_target=24
)
```

---

## üìÇ C·∫•u Tr√∫c File Calibration

```
src/rollrate/
‚îú‚îÄ‚îÄ calibration.py          # Per Product (ƒë∆°n gi·∫£n)
‚îú‚îÄ‚îÄ calibration2.py         # + Seasonality
‚îú‚îÄ‚îÄ calibration_kmob.py     # Per MOB WLS (n√¢ng cao)
‚îî‚îÄ‚îÄ forecast.py             # Forecast engine (d√πng chung)
```

---

## üîß Tham S·ªë C·∫•u H√¨nh Quan Tr·ªçng

**Trong `src/rollrate/calibration.py`:**
```python
H_MAP_CALIB = {
    "CDLPIL": 12,  # MOB anchor ƒë·ªÉ t√≠nh k
    "TWLPIL": 12,
    "SPLPIL": 12,
}

M_APPLY_MAP = {
    "CDLPIL": 4,   # MOB b·∫Øt ƒë·∫ßu √°p k
    "SALPIL": 4,
    "SPLPIL": 4,
}

DEFAULT_M_APPLY = 4
```

**Trong `src/rollrate/calibration_kmob.py`:**
```python
# WLS parameters
min_obs = 5          # S·ªë quan s√°t t·ªëi thi·ªÉu
min_denom = 1e-10    # M·∫´u s·ªë t·ªëi thi·ªÉu
eps = 1e-8           # Epsilon cho zero check

# Smoothing parameters
gamma = 10.0         # Penalty cho second-difference
monotone = False     # √âp k tƒÉng d·∫ßn

# Alpha fitting
alpha_grid = np.arange(0.5, 1.5, 0.01)
val_frac = 0.2       # 20% validation
```

---

## üöÄ Workflow Ho√†n Ch·ªânh (End-to-End)

```python
# 1. Load data
from src.data_loader import load_data
df_raw = load_data("path/to/parquet")

# 2. Build transition matrices
from src.rollrate.transition import compute_transition_by_mob
matrices_by_mob, parent_fallback = compute_transition_by_mob(df_raw)

# 3. Build lifecycle
from src.rollrate.lifecycle import (
    get_actual_all_vintages_amount,
    build_full_lifecycle_amount,
    add_del_metrics
)

actual_results = get_actual_all_vintages_amount(df_raw)
df_lifecycle = build_full_lifecycle_amount(df_raw, matrices_by_mob, max_mob=36)
df_lifecycle = add_del_metrics(df_lifecycle, df_raw)

# 4. Calibration (ch·ªçn 1 trong 3 ph∆∞∆°ng ph√°p)

# Option A: Per Product
from src.rollrate.calibration import (
    compute_k_per_product_ifrs_fullhistory,
    apply_k_to_lifecycle
)
k_dict = compute_k_per_product_ifrs_fullhistory(...)
df_calibrated = apply_k_to_lifecycle(df_lifecycle, k_dict)

# Option B: + Seasonality
from src.rollrate.calibration2 import (
    compute_k_per_product_auto,
    compute_month_seasonality,
    apply_product_calibration,
    apply_month_seasonality
)
k_dict = compute_k_per_product_auto(...)
month_factor = compute_month_seasonality(...)
df_calibrated = apply_product_calibration(df_lifecycle, k_dict)
df_calibrated = apply_month_seasonality(df_calibrated, month_factor)

# Option C: Per MOB WLS
from src.rollrate.calibration_kmob import (
    fit_k_raw,
    smooth_k,
    fit_alpha,
    forecast_all_vintages_partial_step
)
k_raw_by_mob, _, _ = fit_k_raw(...)
k_smooth_by_mob, _, _ = smooth_k(...)
alpha, k_final_by_mob, _ = fit_alpha(...)
forecast_calibrated = forecast_all_vintages_partial_step(..., k_by_mob=k_final_by_mob)

# 5. Export results
from src.rollrate.lifecycle import export_lifecycle_all_products_one_file
export_lifecycle_all_products_one_file(
    df_calibrated,
    actual_info,
    filename="Lifecycle_Calibrated.xlsx"
)
```

---

## üìä Output & Reporting

Sau khi calibration, b·∫°n c√≥ th·ªÉ:

1. **Export Excel v·ªõi heatmap:**
```python
export_lifecycle_all_products_one_file(
    df_del_prod=df_calibrated,
    actual_info=actual_info,
    filename="outputs/Lifecycle_Calibrated.xlsx"
)
```

2. **Aggregate l√™n Product level:**
```python
df_product = aggregate_to_product(df_calibrated)
```

3. **Aggregate l√™n Portfolio level:**
```python
df_portfolio = aggregate_products_to_portfolio(
    df_product,
    portfolio_name="PORTFOLIO_ALL"
)
```

4. **Pivot tables:**
```python
pivot_del30 = make_metric_pivot(df_product, "DEL30_PCT")
pivot_del90 = make_metric_pivot(df_product, "DEL90_PCT")
```

---

## ‚ö†Ô∏è L∆∞u √ù Quan Tr·ªçng

1. **DISB_TOTAL ph·∫£i t√≠nh ƒë√∫ng:**
   - M·ªói loan ch·ªâ ƒë√≥ng g√≥p 1 l·∫ßn DISBURSAL_AMOUNT
   - Sum theo (PRODUCT_TYPE, RISK_SCORE, VINTAGE_DATE)

2. **MOB anchor (H) n√™n ch·ªçn:**
   - 12 cho s·∫£n ph·∫©m ng·∫Øn h·∫°n (< 24 th√°ng)
   - 24 cho s·∫£n ph·∫©m d√†i h·∫°n (> 24 th√°ng)

3. **Blend k ƒë·ªÉ tr√°nh nh·∫£y ƒë·ªôt ng·ªôt:**
   - `blend_n=2`: blend 2 k·ª≥ ƒë·∫ßu
   - MOB < m_apply: k = 1.0
   - MOB = m_apply: k = 0.5 + 0.5*k
   - MOB = m_apply+1: k = 0.75 + 0.25*k
   - MOB >= m_apply+2: k = k

4. **Clip k ƒë·ªÉ tr√°nh outlier:**
   - `clip_min=0.3, clip_max=3.0` (m·∫∑c ƒë·ªãnh)
   - ƒêi·ªÅu ch·ªânh theo business logic

5. **Validation:**
   - Lu√¥n backtest tr√™n out-of-sample data
   - So s√°nh MAE: adjusted vs markov
   - Check k curve c√≥ h·ª£p l√Ω kh√¥ng

---

## üîç Troubleshooting

**V·∫•n ƒë·ªÅ: k qu√° cao/th·∫•p**
- Ki·ªÉm tra H_map (MOB anchor)
- Ki·ªÉm tra DISB_TOTAL c√≥ ƒë√∫ng kh√¥ng
- Th·ª≠ method kh√°c (median thay v√¨ trimmed_mean)

**V·∫•n ƒë·ªÅ: k nh·∫£y ƒë·ªôt ng·ªôt**
- TƒÉng gamma trong smooth_k
- D√πng monotone=True
- TƒÉng blend_n

**V·∫•n ƒë·ªÅ: Forecast sau calibration v·∫´n sai**
- Ki·ªÉm tra m_apply (c√≥ th·ªÉ c·∫ßn √°p s·ªõm h∆°n)
- Th·ª≠ denom_mode="ead" thay v√¨ "disb"
- Fit alpha v·ªõi mob_target kh√°c

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

- `README.md`: T·ªïng quan d·ª± √°n
- `src/rollrate/calibration.py`: Code chi ti·∫øt per product
- `src/rollrate/calibration2.py`: Code chi ti·∫øt + seasonality
- `src/rollrate/calibration_kmob.py`: Code chi ti·∫øt per MOB WLS
- `notebooks/Projection_done.ipynb`: V√≠ d·ª• workflow ƒë·∫ßy ƒë·ªß

---

## üìç Ph·∫ßn 8: PH√ÇN B·ªî NG∆Ø·ª¢C FORECAST XU·ªêNG LOAN-LEVEL

### 1. T·∫°i Sao C·∫ßn Ph√¢n B·ªï Ng∆∞·ª£c?

Sau khi c√≥ k·∫øt qu·∫£ forecast ·ªü cohort-level (PRODUCT_TYPE √ó RISK_SCORE √ó VINTAGE_DATE √ó MOB), b·∫°n c√≥ th·ªÉ c·∫ßn:
- **L·∫•y th√¥ng tin chi ti·∫øt** c·ªßa t·ª´ng h·ª£p ƒë·ªìng (customer info, branch, product details)
- **Ph√¢n t√≠ch r·ªßi ro** theo t·ª´ng loan c·ª• th·ªÉ
- **T·∫°o action list** cho collection team
- **B√°o c√°o chi ti·∫øt** cho regulator

### 2. Hai Ph∆∞∆°ng Ph√°p Ph√¢n B·ªï

#### **A. Proportional Allocation (Chi Ti·∫øt)**

M·ªói loan nh·∫≠n EAD t·ª´ nhi·ªÅu states theo t·ª∑ l·ªá.

**∆Øu ƒëi·ªÉm:**
- Gi·ªØ nguy√™n ph√¢n ph·ªëi state t·ª´ cohort
- T·ªïng EAD kh·ªõp 100%
- Ph·∫£n √°nh ƒë√∫ng uncertainty

**Nh∆∞·ª£c ƒëi·ªÉm:**
- M·ªói loan c√≥ nhi·ªÅu d√≤ng (1 d√≤ng per state)
- Kh√≥ visualize

**Code:**
```python
from src.rollrate.allocation import allocate_forecast_to_loans

df_allocated = allocate_forecast_to_loans(
    df_lifecycle_final=df_lifecycle_final,
    df_raw=df_raw,
    allocation_method="proportional",  # "proportional", "equal", "risk_weighted"
    forecast_only=True,
)
```

#### **B. Simple Allocation (1 State Per Loan)**

M·ªói loan ch·ªâ ƒë∆∞·ª£c assign v√†o 1 state duy nh·∫•t (Monte Carlo sampling).

**∆Øu ƒëi·ªÉm:**
- ƒê∆°n gi·∫£n, d·ªÖ hi·ªÉu
- M·ªói loan ch·ªâ 1 d√≤ng
- D·ªÖ t·∫°o action list

**Nh∆∞·ª£c ƒëi·ªÉm:**
- C√≥ y·∫øu t·ªë random (c·∫ßn set seed)
- T·ªïng EAD c√≥ th·ªÉ ch√™nh nh·∫π do sampling

**Code:**
```python
from src.rollrate.allocation import allocate_forecast_to_loans_simple

df_allocated_simple = allocate_forecast_to_loans_simple(
    df_lifecycle_final=df_lifecycle_final,
    df_raw=df_raw,
    forecast_only=True,
)
```

### 3. Validation: Ki·ªÉm Tra T·ªïng EAD

```python
from src.rollrate.allocation import validate_allocation

compare_df = validate_allocation(
    df_allocated=df_allocated,
    df_lifecycle_final=df_lifecycle_final,
    group_cols=["PRODUCT_TYPE", "RISK_SCORE", "VINTAGE_DATE", "MOB"]
)

# Xem c√°c cohort c√≥ l·ªói
errors = compare_df[compare_df["STATUS"] != "OK"]
print(errors)
```

**Output:**
```
üìä Validation Summary:
OK         1234
WARNING      12
ERROR         0
```

### 4. Enrich: Th√™m Th√¥ng Tin B·ªï Sung

```python
from src.rollrate.allocation import enrich_loan_forecast

additional_cols = [
    "CUSTOMER_ID",
    "CUSTOMER_NAME",
    "BRANCH_CODE",
    "PRODUCT_NAME",
    "LOAN_TERM",
    "INTEREST_RATE",
]

df_enriched = enrich_loan_forecast(
    df_allocated=df_allocated_simple,
    df_raw=df_raw,
    additional_cols=additional_cols,
)
```

### 5. Use Cases

#### **A. T·∫°o Action List cho Collection Team**

```python
# L·ªçc c√°c loan d·ª± b√°o s·∫Ω r∆°i v√†o DPD90+ t·∫°i MOB 12
high_risk_loans = df_enriched[
    (df_enriched["MOB"] == 12) &
    (df_enriched["STATE_FORECAST"].isin(["DPD90+", "DPD120+", "DPD180+", "WRITEOFF"]))
].copy()

# Export cho collection team
high_risk_loans.to_excel(
    "outputs/High_Risk_Loans_MOB12.xlsx",
    columns=["AGREEMENT_ID", "CUSTOMER_NAME", "BRANCH_CODE", 
             "STATE_FORECAST", "EAD_FORECAST", "PHONE_NUMBER"],
    index=False
)
```

#### **B. Ph√¢n T√≠ch Theo Branch**

```python
# T·ªïng EAD r·ªßi ro cao theo branch
branch_risk = (
    high_risk_loans.groupby("BRANCH_CODE")["EAD_FORECAST"]
    .sum()
    .sort_values(ascending=False)
)

print("Top 10 branches c√≥ EAD r·ªßi ro cao nh·∫•t:")
print(branch_risk.head(10))
```

#### **C. Ph√¢n T√≠ch Theo Customer Segment**

```python
# T·ªïng EAD theo customer segment
segment_risk = (
    df_enriched.groupby(["CUSTOMER_SEGMENT", "STATE_FORECAST"])["EAD_FORECAST"]
    .sum()
    .unstack(fill_value=0)
)

print(segment_risk)
```

### 6. Workflow Ho√†n Ch·ªânh

```python
# ===== B∆Ø·ªöC 1: Forecast cohort-level (ƒë√£ c√≥ t·ª´ tr∆∞·ªõc) =====
# df_lifecycle_final = ...

# ===== B∆Ø·ªöC 2: Ph√¢n b·ªï xu·ªëng loan-level =====
df_allocated = allocate_forecast_to_loans_simple(
    df_lifecycle_final=df_lifecycle_final,
    df_raw=df_raw,
    forecast_only=True,
)

# ===== B∆Ø·ªöC 3: Validate =====
compare_df = validate_allocation(df_allocated, df_lifecycle_final)

# ===== B∆Ø·ªöC 4: Enrich =====
df_enriched = enrich_loan_forecast(
    df_allocated=df_allocated,
    df_raw=df_raw,
    additional_cols=["CUSTOMER_ID", "CUSTOMER_NAME", "BRANCH_CODE"],
)

# ===== B∆Ø·ªöC 5: Ph√¢n t√≠ch & Export =====
# T·∫°o action list
high_risk = df_enriched[
    df_enriched["STATE_FORECAST"].isin(["DPD90+", "WRITEOFF"])
]

# Export
with pd.ExcelWriter("outputs/Loan_Level_Forecast.xlsx") as writer:
    df_enriched.to_excel(writer, sheet_name="All_Loans", index=False)
    high_risk.to_excel(writer, sheet_name="High_Risk", index=False)
    compare_df.to_excel(writer, sheet_name="Validation", index=False)
```

### 7. L∆∞u √ù Quan Tr·ªçng

1. **Allocation Method:**
   - D√πng `"proportional"` n·∫øu c·∫ßn gi·ªØ nguy√™n ph√¢n ph·ªëi state
   - D√πng `"simple"` n·∫øu c·∫ßn 1 state per loan (d·ªÖ action)
   - D√πng `"equal"` n·∫øu mu·ªën ph√¢n b·ªï ƒë·ªÅu (√≠t d√πng)

2. **Validation:**
   - Lu√¥n ch·∫°y `validate_allocation()` sau khi ph√¢n b·ªï
   - Ch√™nh l·ªách < 0.1% l√† OK
   - Ch√™nh l·ªách > 1% c·∫ßn ki·ªÉm tra l·∫°i

3. **Performance:**
   - V·ªõi data l·ªõn (> 1M loans), d√πng `simple` s·∫Ω nhanh h∆°n
   - C√≥ th·ªÉ filter forecast_only=True ƒë·ªÉ gi·∫£m data

4. **Random Seed:**
   - `simple` method d√πng random sampling
   - ƒê√£ set `np.random.seed(42)` ƒë·ªÉ reproducible
   - C√≥ th·ªÉ thay ƒë·ªïi seed n·∫øu c·∫ßn

### 8. Troubleshooting

**V·∫•n ƒë·ªÅ: T·ªïng EAD kh√¥ng kh·ªõp**
- Ki·ªÉm tra df_lifecycle_final c√≥ ƒë·ªß c√°c c·ªôt state kh√¥ng
- Ki·ªÉm tra df_raw c√≥ ƒë·ªß loans trong cohort kh√¥ng
- Th·ª≠ allocation_method kh√°c

**V·∫•n ƒë·ªÅ: Thi·∫øu loans trong k·∫øt qu·∫£**
- Ki·ªÉm tra VINTAGE_DATE c√≥ kh·ªõp gi·ªØa lifecycle v√† raw kh√¥ng
- Ki·ªÉm tra PRODUCT_TYPE, RISK_SCORE c√≥ kh·ªõp kh√¥ng
- Ki·ªÉm tra cutoff_date (ch·ªâ l·∫•y snapshot m·ªõi nh·∫•t)

**V·∫•n ƒë·ªÅ: Enrich thi·∫øu columns**
- Ki·ªÉm tra additional_cols c√≥ t·ªìn t·∫°i trong df_raw kh√¥ng
- Ki·ªÉm tra loan_id c√≥ unique kh√¥ng (c√≥ th·ªÉ b·ªã duplicate)

---

**T√°c gi·∫£:** Roll Rate Model Team  
**C·∫≠p nh·∫≠t:** 2025-01-15
