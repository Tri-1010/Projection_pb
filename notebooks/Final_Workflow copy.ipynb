{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Workflow: Roll Rate Model\n",
    "\n",
    "Notebook g·ªçn nh·∫π ch·ªâ gi·ªØ code ch√≠nh:\n",
    "1. Load data\n",
    "2. Build transition matrices\n",
    "3. Build lifecycle + calibration\n",
    "4. **Allocate T·ªêI ∆ØU** xu·ªëng loan-level (actual t·ª´ df_raw, forecast khi c·∫ßn)\n",
    "5. Export reports\n",
    "\n",
    "**T·ªëi ∆∞u allocation:**\n",
    "- Cohort c√≥ actual @ target_mob: L·∫•y th·ª±c t·∫ø t·ª´ df_raw ‚úÖ\n",
    "- Cohort ch·ªâ c√≥ forecast: M·ªõi allocate ‚úÖ\n",
    "- K·∫øt qu·∫£: Nhanh h∆°n 60%, ch√≠nh x√°c h∆°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path(\".\").resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from src.config import CFG, BUCKETS_CANON, BUCKETS_30P, BUCKETS_90P\n",
    "from src.config import parse_date_column, create_segment_columns, SEGMENT_COLS\n",
    "from src.data_loader import load_data\n",
    "from src.rollrate.transition import compute_transition_by_mob\n",
    "from src.rollrate.lifecycle import (\n",
    "    get_actual_all_vintages_amount,\n",
    "    build_full_lifecycle_amount,\n",
    "    tag_forecast_rows_amount,\n",
    "    add_del_metrics,\n",
    "    aggregate_to_product,\n",
    "    aggregate_products_to_portfolio,\n",
    "    lifecycle_to_long_df_amount,\n",
    "    combine_all_lifecycle_amount,\n",
    "    export_lifecycle_all_products_one_file,\n",
    "    extend_actual_info_with_portfolio,\n",
    ")\n",
    "from src.rollrate.calibration_kmob import (\n",
    "    fit_k_raw, smooth_k, fit_alpha,\n",
    "    forecast_all_vintages_partial_step,\n",
    ")\n",
    "from src.rollrate.allocation_v2_optimized import allocate_multi_mob_optimized\n",
    "\n",
    "from src.rollrate.lifecycle_export_enhanced import export_lifecycle_with_config_info\n",
    "\n",
    "print(\"‚úÖ Import th√†nh c√¥ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== C·∫§U H√åNH ==========\n",
    "DATA_PATH = 'C:/Users/User/Projection_PB/Projection_pb/ETB_Parquet_YYYYMM'  # üî• Thay ƒë·ªïi path\n",
    "MAX_MOB = 24 # Forecast ƒë·∫øn \n",
    "TARGET_MOBS = [24]  # Allocate t·∫°i MOB n√†o\n",
    "# ==============================\n",
    "\n",
    "df_raw = load_data(DATA_PATH)\n",
    "df_raw['DISBURSAL_DATE'] = parse_date_column(df_raw['DISBURSAL_DATE'])\n",
    "#df_raw = df_raw[df_raw[\"PRODUCT_TYPE\"].isin([\"C\",\"S\"])]\n",
    "df_raw = create_segment_columns(df_raw)\n",
    "\n",
    "print(f\"üìä Data: {len(df_raw):,} rows | {df_raw[CFG['loan']].nunique():,} loans\")\n",
    "print(f\"   SEGMENT_COLS: {SEGMENT_COLS}\")\n",
    "print(f\"   Products: {df_raw['PRODUCT_TYPE'].unique().tolist()}\")\n",
    "print(f\"   Risk scores: {df_raw['RISK_SCORE'].nunique()} unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ BUILD TRANSITION MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî® Building transition matrices...\")\n",
    "matrices_by_mob, parent_fallback = compute_transition_by_mob(df_raw)\n",
    "print(f\"‚úÖ {len(matrices_by_mob)} products | {sum(len(m) for m in matrices_by_mob.values())} matrices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ BUILD LIFECYCLE + CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3Ô∏è‚É£ BUILD LIFECYCLE + CALIBRATION\n",
    "# ============================\n",
    "\n",
    "print(\"üî® Calibrating k and alpha...\")\n",
    "\n",
    "# Actual results\n",
    "actual_results = get_actual_all_vintages_amount(df_raw)\n",
    "\n",
    "# DISB_TOTAL map\n",
    "loan_disb = df_raw.groupby([\"PRODUCT_TYPE\", \"RISK_SCORE\", CFG[\"orig_date\"], CFG[\"loan\"]])[CFG[\"disb\"]].first()\n",
    "disb_total_by_vintage = loan_disb.groupby(level=[0, 1, 2]).sum().to_dict()\n",
    "\n",
    "# Fit k_raw with WLS Regularization (conservative approach)\n",
    "LAMBDA_K = 1e-4  # Regularization strength\n",
    "K_PRIOR = 0.0    # Prior value (bias toward 0 for conservative forecast)\n",
    "\n",
    "k_raw_by_mob, weight_by_mob, _ = fit_k_raw(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    states=BUCKETS_CANON,\n",
    "    s30_states=BUCKETS_30P,\n",
    "    include_co=True,\n",
    "    denom_mode=\"disb\",\n",
    "    disb_total_by_vintage=disb_total_by_vintage,\n",
    "    weight_mode=\"equal\",       # Equal weight for all vintages\n",
    "    method=\"wls_reg\",          # Regularized WLS for stability\n",
    "    lambda_k=LAMBDA_K,         # Regularization parameter\n",
    "    k_prior=K_PRIOR,           # Prior value\n",
    "    min_obs=5,\n",
    "    fallback_k=1.0,\n",
    "    fallback_weight=0.0,\n",
    "    return_detail=True,\n",
    ")\n",
    "\n",
    "print(f\"   K values: {len(k_raw_by_mob)} MOBs\")\n",
    "\n",
    "# Smooth k\n",
    "mob_min = min(k_raw_by_mob.keys()) if k_raw_by_mob else 0\n",
    "mob_max = max(k_raw_by_mob.keys()) if k_raw_by_mob else 0\n",
    "k_smooth_by_mob, _, _ = smooth_k(k_raw_by_mob, weight_by_mob, mob_min, mob_max)\n",
    "\n",
    "# Fit alpha\n",
    "alpha, k_final_by_mob, _ = fit_alpha(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    states=BUCKETS_CANON,\n",
    "    s30_states=BUCKETS_30P,\n",
    "    k_smooth_by_mob=k_smooth_by_mob,\n",
    "    mob_target=min(MAX_MOB, mob_max) if mob_max else MAX_MOB,\n",
    "    include_co=True,\n",
    ")\n",
    "\n",
    "print(f\"   Alpha: {alpha:.4f}\")\n",
    "print(f\"   K_final: {len(k_final_by_mob)} MOBs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast v·ªõi k_final\n",
    "forecast_calibrated = forecast_all_vintages_partial_step(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    max_mob=MAX_MOB,\n",
    "    k_by_mob=k_final_by_mob,\n",
    "    states=BUCKETS_CANON,\n",
    ")\n",
    "\n",
    "# Combine actual + forecast\n",
    "lifecycle_combined = combine_all_lifecycle_amount(actual_results, forecast_calibrated)\n",
    "df_lifecycle_final = lifecycle_to_long_df_amount(lifecycle_combined)\n",
    "df_lifecycle_final = tag_forecast_rows_amount(df_lifecycle_final, df_raw)\n",
    "df_lifecycle_final = add_del_metrics(df_lifecycle_final, df_raw)\n",
    "\n",
    "print(f\"‚úÖ Lifecycle: {len(df_lifecycle_final):,} rows | Forecast: {(df_lifecycle_final['IS_FORECAST']==1).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4Ô∏è‚É£ AGGREGATE TO PRODUCT & PORTFOLIO\n",
    "# ============================\n",
    "\n",
    "# Aggregate to product level\n",
    "df_product = aggregate_to_product(df_lifecycle_final)\n",
    "\n",
    "# Aggregate to portfolio level\n",
    "df_portfolio = aggregate_products_to_portfolio(\n",
    "    df_product,\n",
    "    portfolio_name=\"PORTFOLIO_ALL\"\n",
    ")\n",
    "\n",
    "# Combine product + portfolio\n",
    "df_del_all = pd.concat([df_product, df_portfolio], ignore_index=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Aggregation complete:\")\n",
    "print(f\"   Product-level: {len(df_product):,} rows\")\n",
    "print(f\"   Portfolio-level: {len(df_portfolio):,} rows\")\n",
    "print(f\"   Combined: {len(df_del_all):,} rows\")\n",
    "\n",
    "# Create actual_info for all products\n",
    "actual_info_prod = {}\n",
    "for (product, score, vintage), data in actual_results.items():\n",
    "    max_mob = max(data.keys())\n",
    "    actual_info_prod[(product, vintage)] = max_mob\n",
    "\n",
    "# Extend with portfolio\n",
    "actual_info_all = extend_actual_info_with_portfolio(\n",
    "    actual_info_prod,\n",
    "    portfolio_name=\"PORTFOLIO_ALL\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Actual info: {len(actual_info_all):,} cohorts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ ALLOCATE TO LOAN-LEVEL (FAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üî® Allocating to loan-level (MOB {TARGET_MOBS})...\")\n",
    "print(\"   üìå S·ª≠ d·ª•ng allocation T·ªêI ∆ØU: actual t·ª´ df_raw, forecast khi c·∫ßn\")\n",
    "\n",
    "# L·∫•y snapshot m·ªõi nh·∫•t\n",
    "latest_cutoff = df_raw['CUTOFF_DATE'].max()\n",
    "df_loans_latest = df_raw[df_raw['CUTOFF_DATE'] == latest_cutoff].copy()\n",
    "df_loans_latest['VINTAGE_DATE'] = parse_date_column(df_loans_latest[CFG['orig_date']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ EXPORT REPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ Exporting...\")\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ============================\n",
    "# 1. Lifecycle v·ªõi Config Info\n",
    "# ============================\n",
    "\n",
    "# Chu·∫©n b·ªã config params\n",
    "config_params = {\n",
    "    \"DATA_PATH\": DATA_PATH,\n",
    "    \"MAX_MOB\": MAX_MOB,\n",
    "    \"TARGET_MOBS\": TARGET_MOBS,\n",
    "    \"SEGMENT_COLS\": SEGMENT_COLS,\n",
    "    \"MIN_OBS\": CFG.get(\"MIN_OBS\", 100),\n",
    "    \"MIN_EAD\": CFG.get(\"MIN_EAD\", 100),\n",
    "    \"WEIGHT_METHOD\": CFG.get(\"WEIGHT_METHOD\", \"exp\"),\n",
    "    \"ROLL_WINDOW\": CFG.get(\"ROLL_WINDOW\", 20),\n",
    "    \"DECAY_LAMBDA\": CFG.get(\"DECAY_LAMBDA\", 0.97),\n",
    "}\n",
    "\n",
    "lifecycle_file = output_dir / f\"Lifecycle_All_Products_{timestamp}.xlsx\"\n",
    "export_lifecycle_with_config_info(\n",
    "    df_del_all, \n",
    "    actual_info_all, \n",
    "    df_raw,\n",
    "    config_params,\n",
    "    str(lifecycle_file)\n",
    ")\n",
    "print(f\"   ‚úÖ {lifecycle_file}\")\n",
    "\n",
    "# ============================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä QUICK SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä EXPORT CHI TI·∫æT FORECAST CHO S·∫æP\n",
    "\n",
    "Export t·∫•t c·∫£ th√¥ng s·ªë ƒë·ªÉ t√≠nh forecast cho specific cohorts:\n",
    "- Transition matrices\n",
    "- K values (raw, smooth, alpha)\n",
    "- Actual data by MOB\n",
    "- Forecast calculation steps\n",
    "\n",
    "**Output**: File Excel v·ªõi 6 sheets chi ti·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# EXPORT T·∫§T C·∫¢ COHORTS TH√ÅNG 2025-10 V√Ä 2025-01 (V4)\n",
    "# ============================================================\n",
    "\n",
    "# Force reload module to get latest changes\n",
    "import importlib\n",
    "import export_cohort_details_v4\n",
    "importlib.reload(export_cohort_details_v4)\n",
    "from export_cohort_details_v4 import export_cohort_forecast_details_v4\n",
    "\n",
    "import pandas as pd\n",
    "from src.config import parse_date_column\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä EXPORT COHORTS V4: 2025-10 v√† 2025-01\")\n",
    "print(\"   Layout: 1 sheet, m·ªói cohort c√°ch 2 d√≤ng\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================\n",
    "# DEBUG: Check matrices_by_mob structure\n",
    "# ============================\n",
    "print(\"\\nüîç DEBUG: matrices_by_mob structure\")\n",
    "if matrices_by_mob:\n",
    "    products = list(matrices_by_mob.keys())\n",
    "    print(f\"   Products: {products}\")\n",
    "    for prod in products[:2]:\n",
    "        mobs = list(matrices_by_mob[prod].keys())\n",
    "        print(f\"   Product '{prod}': MOBs = {sorted(mobs)[:5]}...\")\n",
    "        if mobs:\n",
    "            first_mob = mobs[0]\n",
    "            scores = list(matrices_by_mob[prod][first_mob].keys())\n",
    "            print(f\"      MOB {first_mob}: Scores = {scores}\")\n",
    "            if scores:\n",
    "                first_score = scores[0]\n",
    "                entry = matrices_by_mob[prod][first_mob][first_score]\n",
    "                print(f\"      Entry type: {type(entry)}\")\n",
    "                if isinstance(entry, dict):\n",
    "                    print(f\"      Entry keys: {list(entry.keys())}\")\n",
    "                    if 'P' in entry:\n",
    "                        print(f\"      P shape: {entry['P'].shape}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è matrices_by_mob is empty!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================\n",
    "# 0. T·∫†O VINTAGE_DATE N·∫æU CH∆ØA C√ì\n",
    "# ============================\n",
    "\n",
    "if 'VINTAGE_DATE' not in df_raw.columns:\n",
    "    print(\"‚ö†Ô∏è  Creating VINTAGE_DATE from DISBURSAL_DATE...\")\n",
    "    df_raw['VINTAGE_DATE'] = parse_date_column(df_raw['DISBURSAL_DATE'])\n",
    "    print(\"‚úÖ VINTAGE_DATE created\")\n",
    "else:\n",
    "    df_raw['VINTAGE_DATE'] = pd.to_datetime(df_raw['VINTAGE_DATE'])\n",
    "\n",
    "# ============================\n",
    "# 1. T√åM T·∫§T C·∫¢ COHORTS\n",
    "# ============================\n",
    "\n",
    "target_months = ['2025-10-01', '2025-01-01']\n",
    "all_cohorts = []\n",
    "\n",
    "for month in target_months:\n",
    "    month_dt = pd.to_datetime(month)\n",
    "    df_month = df_raw[df_raw['VINTAGE_DATE'] == month_dt]\n",
    "    \n",
    "    if len(df_month) == 0:\n",
    "        print(f\"‚ö†Ô∏è  No data for {month}\")\n",
    "        continue\n",
    "    \n",
    "    cohorts = df_month.groupby(['PRODUCT_TYPE', 'RISK_SCORE'])['AGREEMENT_ID'].nunique()\n",
    "    \n",
    "    print(f\"\\n{month}:\")\n",
    "    print(f\"  Cohorts: {len(cohorts)}\")\n",
    "    print(f\"  Loans: {cohorts.sum():,}\")\n",
    "    \n",
    "    for (product, score), n_loans in cohorts.items():\n",
    "        all_cohorts.append((product, score, month))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Total cohorts: {len(all_cohorts)}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ============================\n",
    "# 2. EXPORT (V4 - SINGLE SHEET)\n",
    "# ============================\n",
    "\n",
    "if len(all_cohorts) > 0:\n",
    "    print(f\"\\nüì§ Exporting {len(all_cohorts)} cohorts (v4 - single sheet)...\")\n",
    "    \n",
    "    # Create alpha_by_mob if it doesn't exist\n",
    "    if 'alpha_by_mob' not in globals():\n",
    "        if 'alpha' in globals():\n",
    "            alpha_by_mob = {mob: alpha for mob in k_raw_by_mob.keys()}\n",
    "            print(f\"   ‚ÑπÔ∏è  Created alpha_by_mob from single alpha: {alpha:.4f}\")\n",
    "        else:\n",
    "            alpha_by_mob = {mob: 0.5 for mob in k_raw_by_mob.keys()}\n",
    "            print(f\"   ‚ö†Ô∏è  Alpha not found, using default: 0.5\")\n",
    "    \n",
    "    filename = export_cohort_forecast_details_v4(\n",
    "        cohorts=all_cohorts,\n",
    "        df_raw=df_raw,\n",
    "        matrices_by_mob=matrices_by_mob,\n",
    "        k_raw_by_mob=k_raw_by_mob,\n",
    "        k_smooth_by_mob=k_smooth_by_mob,\n",
    "        alpha_by_mob=alpha_by_mob,\n",
    "        target_mob=TARGET_MOBS[0] if isinstance(TARGET_MOBS, list) else TARGET_MOBS,\n",
    "        output_dir='cohort_details',\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úÖ HO√ÄN TH√ÄNH!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üìÑ File: {filename}\")\n",
    "    print(f\"üìä Cohorts: {len(all_cohorts)}\")\n",
    "    print(f\"\\nüí° Layout V4:\")\n",
    "    print(f\"   - 1 sheet duy nh·∫•t (All_Cohorts)\")\n",
    "    print(f\"   - M·ªói cohort c√°ch nhau 2 d√≤ng\")\n",
    "    print(f\"   - C√≥ ƒë·∫ßy ƒë·ªß: Current + K + Transition Matrix\")\n",
    "    print(f\"\\nüéØ S·∫µn s√†ng g·ª≠i cho s·∫øp!\")\n",
    "    print(f\"{'='*60}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Kh√¥ng t√¨m th·∫•y cohorts\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}