{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Workflow: Roll Rate Model\n",
    "\n",
    "Notebook g·ªçn nh·∫π ch·ªâ gi·ªØ code ch√≠nh:\n",
    "1. Load data\n",
    "2. Build transition matrices\n",
    "3. Build lifecycle + calibration\n",
    "4. **Allocate T·ªêI ∆ØU** xu·ªëng loan-level (actual t·ª´ df_raw, forecast khi c·∫ßn)\n",
    "5. Export reports\n",
    "\n",
    "**T·ªëi ∆∞u allocation:**\n",
    "- Cohort c√≥ actual @ target_mob: L·∫•y th·ª±c t·∫ø t·ª´ df_raw ‚úÖ\n",
    "- Cohort ch·ªâ c√≥ forecast: M·ªõi allocate ‚úÖ\n",
    "- K·∫øt qu·∫£: Nhanh h∆°n 60%, ch√≠nh x√°c h∆°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path(\".\").resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from src.config import CFG, BUCKETS_CANON, BUCKETS_30P, BUCKETS_90P\n",
    "from src.config import parse_date_column, create_segment_columns, SEGMENT_COLS\n",
    "from src.config import K_POST_MATURE  # K value cho MOB > TARGET_MOB\n",
    "from src.data_loader import load_data\n",
    "from src.rollrate.transition import compute_transition_by_mob\n",
    "from src.rollrate.lifecycle import (\n",
    "    get_actual_all_vintages_amount,\n",
    "    build_full_lifecycle_amount,\n",
    "    tag_forecast_rows_amount,\n",
    "    add_del_metrics,\n",
    "    aggregate_to_product,\n",
    "    aggregate_products_to_portfolio,\n",
    "    lifecycle_to_long_df_amount,\n",
    "    combine_all_lifecycle_amount,\n",
    "    export_lifecycle_all_products_one_file,\n",
    "    extend_actual_info_with_portfolio,\n",
    ")\n",
    "from src.rollrate.calibration_kmob import (\n",
    "    fit_k_raw, smooth_k, fit_alpha,\n",
    "    forecast_all_vintages_partial_step,\n",
    ")\n",
    "from src.rollrate.allocation_v2_optimized import allocate_multi_mob_optimized\n",
    "\n",
    "from src.rollrate.lifecycle_export_enhanced import export_lifecycle_with_config_info\n",
    "\n",
    "print(\"‚úÖ Import th√†nh c√¥ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== C·∫§U H√åNH ==========\n",
    "DATA_PATH = 'C:/Users/User/Projection_PB/Projection_pb/POS_Parquet_YYYYMM'  # üî• Thay ƒë·ªïi path\n",
    "MAX_MOB = 24 # Forecast ƒë·∫øn \n",
    "TARGET_MOBS = [12]  # Allocate t·∫°i MOB n√†o\n",
    "# ==============================\n",
    "\n",
    "df_raw = load_data(DATA_PATH)\n",
    "df_raw['DISBURSAL_DATE'] = parse_date_column(df_raw['DISBURSAL_DATE'])\n",
    "#df_raw = df_raw[df_raw[\"PRODUCT_TYPE\"].isin([\"C\",\"S\"])]\n",
    "df_raw = create_segment_columns(df_raw)\n",
    "\n",
    "print(f\"üìä Data: {len(df_raw):,} rows | {df_raw[CFG['loan']].nunique():,} loans\")\n",
    "print(f\"   SEGMENT_COLS: {SEGMENT_COLS}\")\n",
    "print(f\"   Products: {df_raw['PRODUCT_TYPE'].unique().tolist()}\")\n",
    "print(f\"   Risk scores: {df_raw['RISK_SCORE'].nunique()} unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ BUILD TRANSITION MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî® Building transition matrices...\")\n",
    "matrices_by_mob, parent_fallback = compute_transition_by_mob(df_raw)\n",
    "print(f\"‚úÖ {len(matrices_by_mob)} products | {sum(len(m) for m in matrices_by_mob.values())} matrices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ BUILD LIFECYCLE + CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3Ô∏è‚É£ BUILD LIFECYCLE + CALIBRATION\n",
    "# ============================\n",
    "\n",
    "print(\"üî® Calibrating k and alpha...\")\n",
    "\n",
    "# Actual results\n",
    "actual_results = get_actual_all_vintages_amount(df_raw)\n",
    "\n",
    "# DISB_TOTAL map\n",
    "loan_disb = df_raw.groupby([\"PRODUCT_TYPE\", \"RISK_SCORE\", CFG[\"orig_date\"], CFG[\"loan\"]])[CFG[\"disb\"]].first()\n",
    "disb_total_by_vintage = loan_disb.groupby(level=[0, 1, 2]).sum().to_dict()\n",
    "\n",
    "# Fit k_raw with WLS Regularization (conservative approach)\n",
    "LAMBDA_K = 1e-4  # Regularization strength\n",
    "K_PRIOR = 0.0    # Prior value (bias toward 0 for conservative forecast)\n",
    "\n",
    "k_raw_by_mob, weight_by_mob, _ = fit_k_raw(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    states=BUCKETS_CANON,\n",
    "    s30_states=BUCKETS_30P,\n",
    "    include_co=True,\n",
    "    denom_mode=\"disb\",\n",
    "    disb_total_by_vintage=disb_total_by_vintage,\n",
    "    weight_mode=\"equal\",       # Equal weight for all vintages\n",
    "    method=\"wls_reg\",          # Regularized WLS for stability\n",
    "    lambda_k=LAMBDA_K,         # Regularization parameter\n",
    "    k_prior=K_PRIOR,           # Prior value\n",
    "    min_obs=5,\n",
    "    fallback_k=1.0,\n",
    "    fallback_weight=0.0,\n",
    "    return_detail=True,\n",
    ")\n",
    "\n",
    "print(f\"   K values: {len(k_raw_by_mob)} MOBs\")\n",
    "\n",
    "# Smooth k\n",
    "mob_min = min(k_raw_by_mob.keys()) if k_raw_by_mob else 0\n",
    "mob_max = max(k_raw_by_mob.keys()) if k_raw_by_mob else 0\n",
    "k_smooth_by_mob, _, _ = smooth_k(k_raw_by_mob, weight_by_mob, mob_min, mob_max)\n",
    "\n",
    "# Fit alpha\n",
    "alpha, k_final_by_mob, _ = fit_alpha(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    states=BUCKETS_CANON,\n",
    "    s30_states=BUCKETS_30P,\n",
    "    k_smooth_by_mob=k_smooth_by_mob,\n",
    "    mob_target=min(MAX_MOB, mob_max) if mob_max else MAX_MOB,\n",
    "    include_co=True,\n",
    ")\n",
    "\n",
    "print(f\"   Alpha: {alpha:.4f}\")\n",
    "print(f\"   K_final: {len(k_final_by_mob)} MOBs\")\n",
    "\n",
    "# ============================\n",
    "# APPLY K_POST_MATURE (n·∫øu ƒë∆∞·ª£c c·∫•u h√¨nh)\n",
    "# ============================\n",
    "# K_POST_MATURE: Gi√° tr·ªã K c·ªë ƒë·ªãnh cho MOB > TARGET_MOB\n",
    "# M·ª•c ƒë√≠ch: Gi·∫£m slope c·ªßa DEL curve sau khi mature\n",
    "# V√¨ K tƒÉng d·∫ßn ƒë·∫øn 1.0 s·∫Ω l√†m slope tƒÉng d√π P_m ƒë√£ ·ªïn ƒë·ªãnh\n",
    "\n",
    "if K_POST_MATURE is not None:\n",
    "    target_mob = TARGET_MOBS[0] if isinstance(TARGET_MOBS, list) else TARGET_MOBS\n",
    "    print(f\"\\nüîß Applying K_POST_MATURE = {K_POST_MATURE} for MOB >= {target_mob}\")\n",
    "    \n",
    "    # L∆∞u K tr∆∞·ªõc khi thay ƒë·ªïi ƒë·ªÉ so s√°nh\n",
    "    k_before = {mob: k_final_by_mob.get(mob, 1.0) for mob in range(target_mob, MAX_MOB + 1)}\n",
    "    \n",
    "    # Apply K_POST_MATURE cho MOB >= TARGET_MOB\n",
    "    for mob in range(target_mob, MAX_MOB + 1):\n",
    "        k_final_by_mob[mob] = K_POST_MATURE\n",
    "    \n",
    "    # In so s√°nh\n",
    "    print(f\"   K values comparison (MOB {target_mob} ‚Üí {MAX_MOB}):\")\n",
    "    print(f\"   {'MOB':<6} {'Before':<10} {'After':<10}\")\n",
    "    print(f\"   {'-'*26}\")\n",
    "    for mob in range(target_mob, min(target_mob + 5, MAX_MOB + 1)):\n",
    "        k_old = k_before.get(mob, 1.0)\n",
    "        k_new = k_final_by_mob.get(mob, 1.0)\n",
    "        marker = '‚Üê TARGET_MOB' if mob == target_mob else ''\n",
    "        print(f\"   {mob:<6} {k_old:<10.4f} {k_new:<10.4f} {marker}\")\n",
    "    if MAX_MOB > target_mob + 5:\n",
    "        print(f\"   ...\")\n",
    "        print(f\"   {MAX_MOB:<6} {k_before.get(MAX_MOB, 1.0):<10.4f} {k_final_by_mob.get(MAX_MOB, 1.0):<10.4f}\")\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ K_POST_MATURE applied: MOB {target_mob} ‚Üí {MAX_MOB} = {K_POST_MATURE}\")\n",
    "else:\n",
    "    print(f\"\\n   ‚ÑπÔ∏è  K_POST_MATURE = None, using calibrated K values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast v·ªõi k_final\n",
    "forecast_calibrated = forecast_all_vintages_partial_step(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    max_mob=MAX_MOB,\n",
    "    k_by_mob=k_final_by_mob,\n",
    "    states=BUCKETS_CANON,\n",
    ")\n",
    "\n",
    "# Combine actual + forecast\n",
    "lifecycle_combined = combine_all_lifecycle_amount(actual_results, forecast_calibrated)\n",
    "df_lifecycle_final = lifecycle_to_long_df_amount(lifecycle_combined)\n",
    "df_lifecycle_final = tag_forecast_rows_amount(df_lifecycle_final, df_raw)\n",
    "df_lifecycle_final = add_del_metrics(df_lifecycle_final, df_raw)\n",
    "\n",
    "print(f\"‚úÖ Lifecycle: {len(df_lifecycle_final):,} rows | Forecast: {(df_lifecycle_final['IS_FORECAST']==1).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4Ô∏è‚É£ AGGREGATE TO PRODUCT & PORTFOLIO\n",
    "# ============================\n",
    "\n",
    "# Aggregate to product level\n",
    "df_product = aggregate_to_product(df_lifecycle_final)\n",
    "\n",
    "# Aggregate to portfolio level\n",
    "df_portfolio = aggregate_products_to_portfolio(\n",
    "    df_product,\n",
    "    portfolio_name=\"PORTFOLIO_ALL\"\n",
    ")\n",
    "\n",
    "# Combine product + portfolio\n",
    "df_del_all = pd.concat([df_product, df_portfolio], ignore_index=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Aggregation complete:\")\n",
    "print(f\"   Product-level: {len(df_product):,} rows\")\n",
    "print(f\"   Portfolio-level: {len(df_portfolio):,} rows\")\n",
    "print(f\"   Combined: {len(df_del_all):,} rows\")\n",
    "\n",
    "# Create actual_info for all products\n",
    "actual_info_prod = {}\n",
    "for (product, score, vintage), data in actual_results.items():\n",
    "    max_mob = max(data.keys())\n",
    "    actual_info_prod[(product, vintage)] = max_mob\n",
    "\n",
    "# Extend with portfolio\n",
    "actual_info_all = extend_actual_info_with_portfolio(\n",
    "    actual_info_prod,\n",
    "    portfolio_name=\"PORTFOLIO_ALL\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Actual info: {len(actual_info_all):,} cohorts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ ALLOCATE TO LOAN-LEVEL (FAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üî® Allocating to loan-level (MOB {TARGET_MOBS})...\")\n",
    "print(\"   üìå S·ª≠ d·ª•ng allocation T·ªêI ∆ØU: actual t·ª´ df_raw, forecast khi c·∫ßn\")\n",
    "\n",
    "# L·∫•y snapshot m·ªõi nh·∫•t\n",
    "latest_cutoff = df_raw['CUTOFF_DATE'].max()\n",
    "df_loans_latest = df_raw[df_raw['CUTOFF_DATE'] == latest_cutoff].copy()\n",
    "df_loans_latest['VINTAGE_DATE'] = parse_date_column(df_loans_latest[CFG['orig_date']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ EXPORT REPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ Exporting...\")\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ============================\n",
    "# 1. Lifecycle v·ªõi Config Info\n",
    "# ============================\n",
    "\n",
    "# Chu·∫©n b·ªã config params\n",
    "config_params = {\n",
    "    \"DATA_PATH\": DATA_PATH,\n",
    "    \"MAX_MOB\": MAX_MOB,\n",
    "    \"TARGET_MOBS\": TARGET_MOBS,\n",
    "    \"SEGMENT_COLS\": SEGMENT_COLS,\n",
    "    \"MIN_OBS\": CFG.get(\"MIN_OBS\", 100),\n",
    "    \"MIN_EAD\": CFG.get(\"MIN_EAD\", 100),\n",
    "    \"WEIGHT_METHOD\": CFG.get(\"WEIGHT_METHOD\", \"exp\"),\n",
    "    \"ROLL_WINDOW\": CFG.get(\"ROLL_WINDOW\", 20),\n",
    "    \"DECAY_LAMBDA\": CFG.get(\"DECAY_LAMBDA\", 0.97),\n",
    "}\n",
    "\n",
    "lifecycle_file = output_dir / f\"Lifecycle_All_Products_{timestamp}.xlsx\"\n",
    "export_lifecycle_with_config_info(\n",
    "    df_del_all, \n",
    "    actual_info_all, \n",
    "    df_raw,\n",
    "    config_params,\n",
    "    str(lifecycle_file)\n",
    ")\n",
    "print(f\"   ‚úÖ {lifecycle_file}\")\n",
    "\n",
    "# ============================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä MODEL EVALUATION & VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 T·∫°i sao c·∫ßn h·ªá s·ªë K?\n",
    "\n",
    "**V·∫•n ƒë·ªÅ v·ªõi Markov Chain thu·∫ßn t√∫y:**\n",
    "- Transition Matrix ch·ªâ d·ª± ƒëo√°n x√°c su·∫•t chuy·ªÉn ƒë·ªïi tr·∫°ng th√°i\n",
    "- Kh√¥ng t√≠nh ƒë·∫øn c√°c y·∫øu t·ªë kinh t·∫ø vƒ© m√¥, seasonality\n",
    "- C√≥ th·ªÉ over/under-estimate DEL rates\n",
    "\n",
    "**H·ªá s·ªë K ƒëi·ªÅu ch·ªânh:**\n",
    "- K > 1: Model ƒëang under-estimate ‚Üí c·∫ßn scale up\n",
    "- K < 1: Model ƒëang over-estimate ‚Üí c·∫ßn scale down\n",
    "- K ‚âà 1: Model d·ª± ƒëo√°n t·ªët"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.1 VISUALIZATION: K VALUES BY MOB\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: K_raw vs K_smooth\n",
    "ax1 = axes[0]\n",
    "mobs = sorted(k_raw_by_mob.keys())\n",
    "k_raw_values = [k_raw_by_mob.get(m, np.nan) for m in mobs]\n",
    "k_smooth_values = [k_smooth_by_mob.get(m, np.nan) for m in mobs]\n",
    "\n",
    "ax1.plot(mobs, k_raw_values, 'o-', label='K_raw', alpha=0.7, markersize=6)\n",
    "ax1.plot(mobs, k_smooth_values, 's-', label='K_smooth', alpha=0.9, linewidth=2)\n",
    "ax1.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='K=1 (no adjustment)')\n",
    "ax1.set_xlabel('MOB', fontsize=12)\n",
    "ax1.set_ylabel('K Value', fontsize=12)\n",
    "ax1.set_title('üìä K Values by MOB\\n(Calibration Factor)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: K distribution\n",
    "ax2 = axes[1]\n",
    "k_raw_clean = [v for v in k_raw_values if not np.isnan(v)]\n",
    "ax2.hist(k_raw_clean, bins=20, alpha=0.7, edgecolor='black', label='K_raw distribution')\n",
    "ax2.axvline(x=1.0, color='red', linestyle='--', linewidth=2, label='K=1')\n",
    "ax2.axvline(x=np.mean(k_raw_clean), color='green', linestyle='-', linewidth=2, label=f'Mean K={np.mean(k_raw_clean):.3f}')\n",
    "ax2.set_xlabel('K Value', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title('üìä Distribution of K Values\\n(Why K matters)', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/k_values_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä K Statistics:\")\n",
    "print(f\"   Mean K_raw: {np.mean(k_raw_clean):.4f}\")\n",
    "print(f\"   Std K_raw: {np.std(k_raw_clean):.4f}\")\n",
    "print(f\"   Min K_raw: {np.min(k_raw_clean):.4f}\")\n",
    "print(f\"   Max K_raw: {np.max(k_raw_clean):.4f}\")\n",
    "print(f\"   Alpha: {alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Model Accuracy Metrics (MAE, MAPE, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.2 CALCULATE MODEL ACCURACY METRICS\n",
    "# ============================================================\n",
    "\n",
    "def calculate_metrics(actual, forecast):\n",
    "    \"\"\"Calculate MAE, MAPE, RMSE\"\"\"\n",
    "    actual = np.array(actual)\n",
    "    forecast = np.array(forecast)\n",
    "    \n",
    "    # Remove zeros for MAPE calculation\n",
    "    mask = actual != 0\n",
    "    \n",
    "    mae = np.mean(np.abs(actual - forecast))\n",
    "    rmse = np.sqrt(np.mean((actual - forecast) ** 2))\n",
    "    \n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((actual[mask] - forecast[mask]) / actual[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    \n",
    "    return mae, mape, rmse\n",
    "\n",
    "# Prepare data for comparison\n",
    "# Filter only rows where we have both actual and forecast\n",
    "df_eval = df_lifecycle_final[df_lifecycle_final['IS_FORECAST'] == 0].copy()\n",
    "\n",
    "# We need to compare forecast vs actual for the same cohort/MOB\n",
    "# This requires running forecast WITHOUT using actual data (backtest)\n",
    "\n",
    "print(\"üìä Preparing backtest data...\")\n",
    "\n",
    "# For demonstration, we'll compare DEL30+ rates\n",
    "if 'DEL30_RATE' in df_eval.columns:\n",
    "    actual_del30 = df_eval.groupby('MOB')['DEL30_RATE'].mean()\n",
    "    print(f\"\\nüìà Average DEL30+ Rate by MOB (Actual):\")\n",
    "    print(actual_del30.head(10))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è DEL30_RATE column not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3 BACKTEST: Compare Forecast vs Actual\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîÑ Running backtest comparison...\")\n",
    "\n",
    "# Get cohorts that have actual data at multiple MOBs\n",
    "backtest_results = []\n",
    "\n",
    "for (product, score, vintage), actual_data in actual_results.items():\n",
    "    max_actual_mob = max(actual_data.keys())\n",
    "    \n",
    "    if max_actual_mob < 6:  # Need at least 6 MOBs for meaningful comparison\n",
    "        continue\n",
    "    \n",
    "    # For each MOB, compare actual vs what forecast would have predicted\n",
    "    for mob in range(3, max_actual_mob + 1):\n",
    "        if mob not in actual_data:\n",
    "            continue\n",
    "        \n",
    "        actual_amounts = actual_data[mob]\n",
    "        \n",
    "        # actual_amounts is a pd.Series, not dict\n",
    "        # Calculate DEL30+ from actual\n",
    "        del30_actual = 0\n",
    "        for s in BUCKETS_30P:\n",
    "            if s in actual_amounts.index:\n",
    "                del30_actual += actual_amounts[s]\n",
    "        \n",
    "        total_actual = actual_amounts.sum()\n",
    "        \n",
    "        if total_actual > 0:\n",
    "            del30_rate_actual = del30_actual / total_actual\n",
    "        else:\n",
    "            del30_rate_actual = 0\n",
    "        \n",
    "        backtest_results.append({\n",
    "            'product': product,\n",
    "            'score': score,\n",
    "            'vintage': vintage,\n",
    "            'mob': mob,\n",
    "            'del30_actual': del30_actual,\n",
    "            'total_actual': total_actual,\n",
    "            'del30_rate': del30_rate_actual,\n",
    "        })\n",
    "\n",
    "df_backtest = pd.DataFrame(backtest_results)\n",
    "print(f\"‚úÖ Backtest data: {len(df_backtest):,} observations\")\n",
    "print(f\"   Products: {df_backtest['product'].nunique()}\")\n",
    "print(f\"   MOB range: {df_backtest['mob'].min()} - {df_backtest['mob'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.4 VISUALIZATION: Forecast vs Actual by MOB\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: DEL30+ Rate by MOB (Average across all cohorts)\n",
    "ax1 = axes[0, 0]\n",
    "del30_by_mob = df_backtest.groupby('mob')['del30_rate'].agg(['mean', 'std'])\n",
    "ax1.errorbar(del30_by_mob.index, del30_by_mob['mean'], \n",
    "             yerr=del30_by_mob['std'], fmt='o-', capsize=3, \n",
    "             label='Actual DEL30+ Rate', color='blue')\n",
    "ax1.set_xlabel('MOB', fontsize=12)\n",
    "ax1.set_ylabel('DEL30+ Rate', fontsize=12)\n",
    "ax1.set_title('üìä DEL30+ Rate by MOB\\n(Average ¬± Std)', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: DEL30+ Amount by MOB\n",
    "ax2 = axes[0, 1]\n",
    "del30_amt_by_mob = df_backtest.groupby('mob')['del30_actual'].sum() / 1e9  # In billions\n",
    "ax2.bar(del30_amt_by_mob.index, del30_amt_by_mob.values, alpha=0.7, color='coral')\n",
    "ax2.set_xlabel('MOB', fontsize=12)\n",
    "ax2.set_ylabel('DEL30+ Amount (Billions)', fontsize=12)\n",
    "ax2.set_title('üìä DEL30+ Amount by MOB\\n(Total across cohorts)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: DEL30+ Rate by Product\n",
    "ax3 = axes[1, 0]\n",
    "del30_by_product = df_backtest.groupby('product')['del30_rate'].mean().sort_values(ascending=False)\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(del30_by_product)))\n",
    "bars = ax3.barh(del30_by_product.index, del30_by_product.values, color=colors)\n",
    "ax3.set_xlabel('Average DEL30+ Rate', fontsize=12)\n",
    "ax3.set_ylabel('Product', fontsize=12)\n",
    "ax3.set_title('üìä DEL30+ Rate by Product\\n(Risk Ranking)', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 4: Vintage Performance (Heatmap-style)\n",
    "ax4 = axes[1, 1]\n",
    "# Get top 10 vintages by volume\n",
    "top_vintages = df_backtest.groupby('vintage')['total_actual'].sum().nlargest(10).index\n",
    "df_top = df_backtest[df_backtest['vintage'].isin(top_vintages)]\n",
    "pivot = df_top.pivot_table(values='del30_rate', index='vintage', columns='mob', aggfunc='mean')\n",
    "sns.heatmap(pivot, ax=ax4, cmap='RdYlGn_r', annot=False, fmt='.2%', \n",
    "            cbar_kws={'label': 'DEL30+ Rate'})\n",
    "ax4.set_title('üìä DEL30+ Rate Heatmap\\n(Top 10 Vintages by Volume)', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('MOB', fontsize=12)\n",
    "ax4.set_ylabel('Vintage', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/model_evaluation_charts.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.5 FORECAST vs ACTUAL COMPARISON (Lifecycle Data)\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä Comparing Forecast vs Actual from Lifecycle Data...\")\n",
    "\n",
    "# Separate actual and forecast\n",
    "df_actual = df_lifecycle_final[df_lifecycle_final['IS_FORECAST'] == 0].copy()\n",
    "df_forecast = df_lifecycle_final[df_lifecycle_final['IS_FORECAST'] == 1].copy()\n",
    "\n",
    "print(f\"   Actual rows: {len(df_actual):,}\")\n",
    "print(f\"   Forecast rows: {len(df_forecast):,}\")\n",
    "\n",
    "# For cohorts that have both actual and forecast at same MOB\n",
    "# (This happens when we have partial actual data)\n",
    "\n",
    "# Aggregate by MOB for overall comparison\n",
    "if 'DEL30_AMT' in df_actual.columns:\n",
    "    actual_by_mob = df_actual.groupby('MOB').agg({\n",
    "        'DEL30_AMT': 'sum',\n",
    "        'DISB_TOTAL': 'sum'\n",
    "    })\n",
    "    actual_by_mob['DEL30_RATE'] = actual_by_mob['DEL30_AMT'] / actual_by_mob['DISB_TOTAL']\n",
    "    \n",
    "    print(\"\\nüìà Actual DEL30+ by MOB:\")\n",
    "    print(actual_by_mob.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.6 MODEL PERFORMANCE SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# K-factor analysis\n",
    "k_raw_clean = [v for v in k_raw_by_mob.values() if not np.isnan(v)]\n",
    "k_smooth_clean = [v for v in k_smooth_by_mob.values() if not np.isnan(v)]\n",
    "\n",
    "print(\"\\nüìà K-Factor Analysis:\")\n",
    "print(f\"   K_raw Mean: {np.mean(k_raw_clean):.4f}\")\n",
    "print(f\"   K_raw Std: {np.std(k_raw_clean):.4f}\")\n",
    "print(f\"   K_smooth Mean: {np.mean(k_smooth_clean):.4f}\")\n",
    "print(f\"   Alpha (blending): {alpha:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "k_mean = np.mean(k_raw_clean)\n",
    "if k_mean > 1.1:\n",
    "    interpretation = \"Model UNDER-estimates risk ‚Üí K > 1 scales up predictions\"\n",
    "elif k_mean < 0.9:\n",
    "    interpretation = \"Model OVER-estimates risk ‚Üí K < 1 scales down predictions\"\n",
    "else:\n",
    "    interpretation = \"Model predictions are well-calibrated (K ‚âà 1)\"\n",
    "\n",
    "print(f\"\\nüí° Interpretation: {interpretation}\")\n",
    "\n",
    "# Data coverage\n",
    "print(\"\\nüìä Data Coverage:\")\n",
    "print(f\"   Total cohorts: {len(actual_results):,}\")\n",
    "print(f\"   Products: {len(matrices_by_mob)}\")\n",
    "print(f\"   MOB range: {mob_min} - {mob_max}\")\n",
    "print(f\"   Transition matrices: {sum(len(m) for m in matrices_by_mob.values())}\")\n",
    "\n",
    "# Forecast summary\n",
    "print(\"\\nüìä Forecast Summary:\")\n",
    "print(f\"   Total lifecycle rows: {len(df_lifecycle_final):,}\")\n",
    "print(f\"   Actual rows: {(df_lifecycle_final['IS_FORECAST']==0).sum():,}\")\n",
    "print(f\"   Forecast rows: {(df_lifecycle_final['IS_FORECAST']==1).sum():,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.7 VINTAGE CURVE COMPARISON\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä Creating Vintage Curve Comparison...\")\n",
    "\n",
    "# Select a few representative vintages\n",
    "vintages_to_plot = df_backtest.groupby('vintage')['total_actual'].sum().nlargest(5).index.tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(vintages_to_plot)))\n",
    "\n",
    "for i, vintage in enumerate(vintages_to_plot):\n",
    "    df_v = df_backtest[df_backtest['vintage'] == vintage].sort_values('mob')\n",
    "    ax.plot(df_v['mob'], df_v['del30_rate'], 'o-', \n",
    "            label=f'{vintage.strftime(\"%Y-%m\")}', \n",
    "            color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax.set_xlabel('MOB (Months on Book)', fontsize=12)\n",
    "ax.set_ylabel('DEL30+ Rate', fontsize=12)\n",
    "ax.set_title('üìä Vintage Curves: DEL30+ Rate by MOB\\n(Top 5 Vintages by Volume)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Vintage', loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/vintage_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.8 TRANSITION MATRIX VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä Visualizing Transition Matrix...\")\n",
    "\n",
    "# Get a sample transition matrix\n",
    "sample_product = list(matrices_by_mob.keys())[0]\n",
    "sample_mob = list(matrices_by_mob[sample_product].keys())[0]\n",
    "sample_score = list(matrices_by_mob[sample_product][sample_mob].keys())[0]\n",
    "sample_tm = matrices_by_mob[sample_product][sample_mob][sample_score]['P']\n",
    "\n",
    "# Filter to main buckets only (exclude absorbing states for clarity)\n",
    "main_buckets = [b for b in BUCKETS_CANON if b in sample_tm.index and b in sample_tm.columns]\n",
    "tm_filtered = sample_tm.loc[main_buckets, main_buckets]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(tm_filtered, annot=True, fmt='.1%', cmap='YlOrRd', \n",
    "            ax=ax, cbar_kws={'label': 'Transition Probability'},\n",
    "            linewidths=0.5, linecolor='white')\n",
    "\n",
    "ax.set_title(f'üìä Transition Matrix\\n(Product: {sample_product}, MOB: {sample_mob}, Score: {sample_score})', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('To State (t+1)', fontsize=12)\n",
    "ax.set_ylabel('From State (t)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/transition_matrix_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Sample Transition Matrix:\")\n",
    "print(f\"   Product: {sample_product}\")\n",
    "print(f\"   MOB: {sample_mob}\")\n",
    "print(f\"   Score: {sample_score}\")\n",
    "print(f\"   Shape: {sample_tm.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.9 Advanced Model Evaluation (Full Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.9 ADVANCED MODEL EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "# Import evaluation module\n",
    "import importlib\n",
    "import model_evaluation\n",
    "importlib.reload(model_evaluation)\n",
    "from model_evaluation import run_full_evaluation\n",
    "\n",
    "# Run full evaluation\n",
    "eval_results = run_full_evaluation(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    k_raw_by_mob=k_raw_by_mob,\n",
    "    k_smooth_by_mob=k_smooth_by_mob,\n",
    "    k_final_by_mob=k_final_by_mob,\n",
    "    df_lifecycle_final=df_lifecycle_final,\n",
    "    alpha=alpha,\n",
    "    states=BUCKETS_CANON,\n",
    "    s30_states=BUCKETS_30P,\n",
    "    output_dir='outputs',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.10 DISPLAY EVALUATION RESULTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä EVALUATION RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# K Stability\n",
    "print(\"\\nüìà K-Factor Stability:\")\n",
    "k_stab = eval_results['k_stability']\n",
    "print(f\"   Mean K_raw: {k_stab['k_raw_mean']:.4f}\")\n",
    "print(f\"   Std K_raw: {k_stab['k_raw_std']:.4f}\")\n",
    "print(f\"   CV (Coefficient of Variation): {k_stab['k_raw_cv']:.2%}\")\n",
    "print(f\"   Range: [{k_stab['k_raw_min']:.4f}, {k_stab['k_raw_max']:.4f}]\")\n",
    "print(f\"   Assessment: {k_stab['interpretation']}\")\n",
    "\n",
    "# Concentration Risk\n",
    "print(\"\\n‚ö†Ô∏è Concentration Risk:\")\n",
    "conc = eval_results['concentration']\n",
    "print(f\"   HHI Index: {conc.get('hhi', 0):.4f}\")\n",
    "print(f\"   Assessment: {conc.get('hhi_interpretation', 'N/A')}\")\n",
    "print(f\"   Top 1 Product Share: {conc.get('top1_share', 0):.1f}%\")\n",
    "print(f\"   Top 3 Products Share: {conc.get('top3_share', 0):.1f}%\")\n",
    "print(f\"   Highest Risk Product: {conc.get('highest_risk_product', 'N/A')}\")\n",
    "print(f\"   Highest Risk Rate: {conc.get('highest_risk_rate', 0):.2%}\")\n",
    "\n",
    "# Executive Summary\n",
    "print(\"\\nüìã Executive Summary:\")\n",
    "summary = eval_results['summary']\n",
    "print(f\"   Total Cohorts: {summary['portfolio']['total_cohorts']:,}\")\n",
    "print(f\"   Total Exposure: {summary['portfolio']['total_exposure']:,.0f}\")\n",
    "print(f\"   Avg DEL30+ Rate: {summary['portfolio']['avg_del30_rate']:.2%}\")\n",
    "print(f\"   Forecast Ratio: {summary['forecast']['forecast_ratio']:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ All evaluation outputs saved to 'outputs/' folder\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.11 MODEL ACCURACY BY PRODUCT\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä Model Accuracy by Product:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_bt = eval_results['df_backtest']\n",
    "\n",
    "if not df_bt.empty:\n",
    "    # Calculate metrics by product\n",
    "    product_metrics = df_bt.groupby('product').agg({\n",
    "        'del30_rate': ['mean', 'std', 'count'],\n",
    "        'total_actual': 'sum',\n",
    "        'del30_actual': 'sum'\n",
    "    }).round(4)\n",
    "    \n",
    "    product_metrics.columns = ['Avg_DEL30_Rate', 'Std_DEL30_Rate', 'N_Obs', 'Total_Exposure', 'Total_DEL30']\n",
    "    product_metrics['Weighted_DEL30_Rate'] = product_metrics['Total_DEL30'] / product_metrics['Total_Exposure']\n",
    "    product_metrics = product_metrics.sort_values('Weighted_DEL30_Rate', ascending=False)\n",
    "    \n",
    "    print(product_metrics.to_string())\n",
    "    \n",
    "    # Save to Excel\n",
    "    product_metrics.to_excel('outputs/product_metrics.xlsx')\n",
    "    print(\"\\n‚úÖ Product metrics saved to outputs/product_metrics.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.12 FORECAST ACCURACY OVER TIME\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä DEL30+ Rate Trend Over Time:\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: DEL30+ by Vintage (time trend)\n",
    "ax1 = axes[0]\n",
    "if not df_bt.empty:\n",
    "    vintage_trend = df_bt.groupby('vintage').agg({\n",
    "        'del30_rate': 'mean',\n",
    "        'total_actual': 'sum'\n",
    "    }).sort_index()\n",
    "    \n",
    "    ax1.bar(range(len(vintage_trend)), vintage_trend['del30_rate'], alpha=0.7, color='steelblue')\n",
    "    ax1.set_xticks(range(0, len(vintage_trend), max(1, len(vintage_trend)//10)))\n",
    "    ax1.set_xticklabels([v.strftime('%Y-%m') if hasattr(v, 'strftime') else str(v) \n",
    "                        for v in vintage_trend.index[::max(1, len(vintage_trend)//10)]], \n",
    "                       rotation=45, ha='right')\n",
    "    ax1.set_xlabel('Vintage')\n",
    "    ax1.set_ylabel('Average DEL30+ Rate')\n",
    "    ax1.set_title('DEL30+ Rate by Vintage\\n(Time Trend)', fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cumulative DEL30+ Amount\n",
    "ax2 = axes[1]\n",
    "if not df_bt.empty:\n",
    "    mob_cumulative = df_bt.groupby('mob')['del30_actual'].sum().cumsum() / 1e9\n",
    "    ax2.fill_between(mob_cumulative.index, mob_cumulative.values, alpha=0.5, color='coral')\n",
    "    ax2.plot(mob_cumulative.index, mob_cumulative.values, 'o-', color='darkred', linewidth=2)\n",
    "    ax2.set_xlabel('MOB')\n",
    "    ax2.set_ylabel('Cumulative DEL30+ (Billions)')\n",
    "    ax2.set_title('Cumulative DEL30+ by MOB\\n(Risk Build-up)', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/del30_trends.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç DIAGNOSTIC: DEL CURVE ANALYSIS\n",
    "\n",
    "Ch·∫©n ƒëo√°n t·∫°i sao DEL curve tƒÉng li√™n t·ª•c thay v√¨ flatten ·ªü MOB cao.\n",
    "\n",
    "**Ki·ªÉm tra:**\n",
    "1. K values ·ªü MOB 25+\n",
    "2. % cohorts d√πng parent fallback ·ªü MOB 24\n",
    "3. So s√°nh P_24 vs Parent Fallback\n",
    "4. Aggregation effect\n",
    "5. Ph√¢n t√≠ch t·ª´ng cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8.1 IMPORT DIAGNOSTIC SCRIPTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"üì• Importing diagnostic scripts...\")\n",
    "\n",
    "try:\n",
    "    from diagnose_why_increase_after_24 import diagnose_why_increase_after_24\n",
    "    from check_p24_quality import check_p24_quality\n",
    "    from diagnose_del_curve import diagnose_del_curve\n",
    "    print(\"‚úÖ Diagnostic scripts imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing diagnostic scripts: {e}\")\n",
    "    print(\"   Make sure the diagnostic scripts are in the project root directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8.2 RUN MAIN DIAGNOSTIC\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîç Running comprehensive diagnostic...\")\n",
    "print(\"   This will check:\")\n",
    "print(\"   1. K values at MOB 25+\")\n",
    "print(\"   2. % cohorts using fallback at MOB 24\")\n",
    "print(\"   3. P_24 vs Parent Fallback comparison\")\n",
    "print(\"   4. Aggregation effects\")\n",
    "print(\"   5. Individual cohort analysis\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Prepare df_del_product if available\n",
    "df_del_product = None\n",
    "if 'df_product' in globals():\n",
    "    df_del_product = df_product\n",
    "    print(\"‚úÖ Using df_product for aggregation analysis\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  df_product not found, skipping aggregation analysis\")\n",
    "\n",
    "# Run diagnostic\n",
    "try:\n",
    "    diagnose_why_increase_after_24(\n",
    "        matrices_by_mob=matrices_by_mob,\n",
    "        parent_fallback=parent_fallback,\n",
    "        k_final_by_mob=k_final_by_mob,\n",
    "        forecast_results=forecast_calibrated,\n",
    "        disb_total_by_vintage=disb_total_by_vintage,\n",
    "        df_del_product=df_del_product\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error running diagnostic: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8.3 CHECK P_24 QUALITY (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç Checking P_24 Quality for Sample Cohort\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get a sample cohort to check\n",
    "if matrices_by_mob:\n",
    "    sample_product = list(matrices_by_mob.keys())[0]\n",
    "    \n",
    "    if 24 in matrices_by_mob[sample_product]:\n",
    "        sample_score = list(matrices_by_mob[sample_product][24].keys())[0]\n",
    "        \n",
    "        print(f\"\\nüìä Analyzing: Product={sample_product}, Score={sample_score}\")\n",
    "        \n",
    "        try:\n",
    "            P_24, P_parent = check_p24_quality(\n",
    "                matrices_by_mob=matrices_by_mob,\n",
    "                parent_fallback=parent_fallback,\n",
    "                product=sample_product,\n",
    "                score=sample_score\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error checking P_24 quality: {e}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  MOB 24 not found in matrices_by_mob\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  matrices_by_mob is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8.4 VISUALIZE DEL CURVE FOR SAMPLE COHORT\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä Visualizing DEL Curve for Sample Cohort\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get a sample cohort with good data\n",
    "if forecast_calibrated:\n",
    "    # Find a cohort with data at MOB 24\n",
    "    sample_cohort = None\n",
    "    for cohort_key, forecast_data in forecast_calibrated.items():\n",
    "        if 24 in forecast_data and len(forecast_data) > 10:\n",
    "            sample_cohort = cohort_key\n",
    "            break\n",
    "    \n",
    "    if sample_cohort:\n",
    "        product, score, vintage = sample_cohort\n",
    "        print(f\"\\nüìä Analyzing: Product={product}, Score={score}, Vintage={vintage}\")\n",
    "        \n",
    "        try:\n",
    "            diagnose_del_curve(\n",
    "                matrices_by_mob=matrices_by_mob,\n",
    "                parent_fallback=parent_fallback,\n",
    "                k_final_by_mob=k_final_by_mob,\n",
    "                forecast_results=forecast_calibrated,\n",
    "                disb_total_by_vintage=disb_total_by_vintage,\n",
    "                product=product,\n",
    "                score=score,\n",
    "                vintage=vintage\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error visualizing DEL curve: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No suitable cohort found for visualization\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  forecast_calibrated is empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Diagnostic Summary & Next Steps\n",
    "\n",
    "**Based on the diagnostic results above:**\n",
    "\n",
    "#### If K values are too high (K > 0.9 at MOB 25+):\n",
    "```python\n",
    "# Solution: Cap K at MOB 25+\n",
    "for mob in range(25, 37):\n",
    "    if mob in k_final_by_mob:\n",
    "        k_final_by_mob[mob] = min(k_final_by_mob[mob], 0.3)\n",
    "    else:\n",
    "        k_final_by_mob[mob] = 0.3\n",
    "\n",
    "# Re-run forecast with adjusted K\n",
    "forecast_calibrated = forecast_all_vintages_partial_step(\n",
    "    actual_results=actual_results,\n",
    "    matrices_by_mob=matrices_by_mob,\n",
    "    parent_fallback=parent_fallback,\n",
    "    max_mob=MAX_MOB,\n",
    "    k_by_mob=k_final_by_mob,\n",
    "    states=BUCKETS_CANON,\n",
    ")\n",
    "```\n",
    "\n",
    "#### If many cohorts use fallback at MOB 24 (> 30%):\n",
    "```python\n",
    "# Solution A: Increase MIN_OBS/MIN_EAD in src/config.py\n",
    "# MIN_OBS = 200  # Instead of 100\n",
    "# MIN_EAD = 500  # Instead of 100\n",
    "# Then re-run from step 2 (Build Transition Matrices)\n",
    "\n",
    "# Solution B: Force use parent fallback for MOB 25+\n",
    "# See NEXT_STEPS_DIAGNOSIS.md for code modification\n",
    "```\n",
    "\n",
    "#### If aggregation issue:\n",
    "- Check which cohorts are driving the increase\n",
    "- Investigate cohort-level weights\n",
    "- Consider separate forecasts for high-risk cohorts\n",
    "\n",
    "**üìö For detailed solutions, see:**\n",
    "- `NEXT_STEPS_DIAGNOSIS.md` (English)\n",
    "- `HUONG_DAN_CHAY_DIAGNOSTIC.md` (Vietnamese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8.6 APPLY FIX (EXAMPLE - UNCOMMENT TO USE)\n",
    "# ============================================================\n",
    "\n",
    "# Uncomment the solution that matches your diagnostic results\n",
    "\n",
    "# # SOLUTION 1: Cap K at MOB 25+\n",
    "# print(\"üîß Applying Solution 1: Capping K at MOB 25+\")\n",
    "# print(\"\\nK values before:\")\n",
    "# for mob in range(24, 37):\n",
    "#     print(f\"  MOB {mob}: {k_final_by_mob.get(mob, 1.0):.3f}\")\n",
    "\n",
    "# for mob in range(25, 37):\n",
    "#     if mob in k_final_by_mob:\n",
    "#         k_final_by_mob[mob] = min(k_final_by_mob[mob], 0.3)\n",
    "#     else:\n",
    "#         k_final_by_mob[mob] = 0.3\n",
    "\n",
    "# print(\"\\nK values after:\")\n",
    "# for mob in range(24, 37):\n",
    "#     print(f\"  MOB {mob}: {k_final_by_mob.get(mob, 1.0):.3f}\")\n",
    "\n",
    "# # Re-run forecast\n",
    "# print(\"\\nüîÑ Re-running forecast with adjusted K...\")\n",
    "# forecast_calibrated = forecast_all_vintages_partial_step(\n",
    "#     actual_results=actual_results,\n",
    "#     matrices_by_mob=matrices_by_mob,\n",
    "#     parent_fallback=parent_fallback,\n",
    "#     max_mob=MAX_MOB,\n",
    "#     k_by_mob=k_final_by_mob,\n",
    "#     states=BUCKETS_CANON,\n",
    "# )\n",
    "# print(\"‚úÖ Forecast updated with adjusted K\")\n",
    "\n",
    "# # Re-run diagnostic to verify\n",
    "# print(\"\\nüîç Re-running diagnostic to verify fix...\")\n",
    "# diagnose_why_increase_after_24(\n",
    "#     matrices_by_mob=matrices_by_mob,\n",
    "#     parent_fallback=parent_fallback,\n",
    "#     k_final_by_mob=k_final_by_mob,\n",
    "#     forecast_results=forecast_calibrated,\n",
    "#     disb_total_by_vintage=disb_total_by_vintage,\n",
    "#     df_del_product=df_del_product\n",
    "# )\n",
    "\n",
    "print(\"üí° Uncomment the solution code above to apply the fix\")\n",
    "print(\"   Choose the solution based on your diagnostic results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä EXPORT CHI TI·∫æT FORECAST CHO S·∫æP\n",
    "\n",
    "Export t·∫•t c·∫£ th√¥ng s·ªë ƒë·ªÉ t√≠nh forecast cho specific cohorts:\n",
    "- Transition matrices\n",
    "- K values (raw, smooth, alpha)\n",
    "- Actual data by MOB\n",
    "- Forecast calculation steps\n",
    "\n",
    "**Output**: File Excel v·ªõi 6 sheets chi ti·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# EXPORT T·∫§T C·∫¢ COHORTS TH√ÅNG 2025-10 V√Ä 2025-01 (V4)\n",
    "# ============================================================\n",
    "\n",
    "# Force reload module to get latest changes\n",
    "import importlib\n",
    "import export_cohort_details_v4\n",
    "importlib.reload(export_cohort_details_v4)\n",
    "from export_cohort_details_v4 import export_cohort_forecast_details_v4\n",
    "\n",
    "import pandas as pd\n",
    "from src.config import parse_date_column\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä EXPORT COHORTS V4: 2025-10 v√† 2025-01\")\n",
    "print(\"   Layout: 1 sheet, m·ªói cohort c√°ch 2 d√≤ng\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================\n",
    "# DEBUG: Check matrices_by_mob structure\n",
    "# ============================\n",
    "print(\"\\nüîç DEBUG: matrices_by_mob structure\")\n",
    "if matrices_by_mob:\n",
    "    products = list(matrices_by_mob.keys())\n",
    "    print(f\"   Products: {products}\")\n",
    "    for prod in products[:2]:\n",
    "        mobs = list(matrices_by_mob[prod].keys())\n",
    "        print(f\"   Product '{prod}': MOBs = {sorted(mobs)[:5]}...\")\n",
    "        if mobs:\n",
    "            first_mob = mobs[0]\n",
    "            scores = list(matrices_by_mob[prod][first_mob].keys())\n",
    "            print(f\"      MOB {first_mob}: Scores = {scores}\")\n",
    "            if scores:\n",
    "                first_score = scores[0]\n",
    "                entry = matrices_by_mob[prod][first_mob][first_score]\n",
    "                print(f\"      Entry type: {type(entry)}\")\n",
    "                if isinstance(entry, dict):\n",
    "                    print(f\"      Entry keys: {list(entry.keys())}\")\n",
    "                    if 'P' in entry:\n",
    "                        print(f\"      P shape: {entry['P'].shape}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è matrices_by_mob is empty!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================\n",
    "# 0. T·∫†O VINTAGE_DATE N·∫æU CH∆ØA C√ì\n",
    "# ============================\n",
    "\n",
    "if 'VINTAGE_DATE' not in df_raw.columns:\n",
    "    print(\"‚ö†Ô∏è  Creating VINTAGE_DATE from DISBURSAL_DATE...\")\n",
    "    df_raw['VINTAGE_DATE'] = parse_date_column(df_raw['DISBURSAL_DATE'])\n",
    "    print(\"‚úÖ VINTAGE_DATE created\")\n",
    "else:\n",
    "    df_raw['VINTAGE_DATE'] = pd.to_datetime(df_raw['VINTAGE_DATE'])\n",
    "\n",
    "# ============================\n",
    "# 1. T√åM T·∫§T C·∫¢ COHORTS\n",
    "# ============================\n",
    "\n",
    "target_months = ['2025-10-01', '2025-01-01']\n",
    "all_cohorts = []\n",
    "\n",
    "for month in target_months:\n",
    "    month_dt = pd.to_datetime(month)\n",
    "    df_month = df_raw[df_raw['VINTAGE_DATE'] == month_dt]\n",
    "    \n",
    "    if len(df_month) == 0:\n",
    "        print(f\"‚ö†Ô∏è  No data for {month}\")\n",
    "        continue\n",
    "    \n",
    "    cohorts = df_month.groupby(['PRODUCT_TYPE', 'RISK_SCORE'])['AGREEMENT_ID'].nunique()\n",
    "    \n",
    "    print(f\"\\n{month}:\")\n",
    "    print(f\"  Cohorts: {len(cohorts)}\")\n",
    "    print(f\"  Loans: {cohorts.sum():,}\")\n",
    "    \n",
    "    for (product, score), n_loans in cohorts.items():\n",
    "        all_cohorts.append((product, score, month))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Total cohorts: {len(all_cohorts)}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ============================\n",
    "# 2. EXPORT (V4 - SINGLE SHEET)\n",
    "# ============================\n",
    "\n",
    "if len(all_cohorts) > 0:\n",
    "    print(f\"\\nüì§ Exporting {len(all_cohorts)} cohorts (v4 - single sheet)...\")\n",
    "    \n",
    "    # Create alpha_by_mob if it doesn't exist\n",
    "    if 'alpha_by_mob' not in globals():\n",
    "        if 'alpha' in globals():\n",
    "            alpha_by_mob = {mob: alpha for mob in k_raw_by_mob.keys()}\n",
    "            print(f\"   ‚ÑπÔ∏è  Created alpha_by_mob from single alpha: {alpha:.4f}\")\n",
    "        else:\n",
    "            alpha_by_mob = {mob: 0.5 for mob in k_raw_by_mob.keys()}\n",
    "            print(f\"   ‚ö†Ô∏è  Alpha not found, using default: 0.5\")\n",
    "    \n",
    "    filename = export_cohort_forecast_details_v4(\n",
    "        cohorts=all_cohorts,\n",
    "        df_raw=df_raw,\n",
    "        matrices_by_mob=matrices_by_mob,\n",
    "        k_raw_by_mob=k_raw_by_mob,\n",
    "        k_smooth_by_mob=k_smooth_by_mob,\n",
    "        alpha_by_mob=alpha_by_mob,\n",
    "        target_mob=TARGET_MOBS[0] if isinstance(TARGET_MOBS, list) else TARGET_MOBS,\n",
    "        output_dir='cohort_details',\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úÖ HO√ÄN TH√ÄNH!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üìÑ File: {filename}\")\n",
    "    print(f\"üìä Cohorts: {len(all_cohorts)}\")\n",
    "    print(f\"\\nüí° Layout V4:\")\n",
    "    print(f\"   - 1 sheet duy nh·∫•t (All_Cohorts)\")\n",
    "    print(f\"   - M·ªói cohort c√°ch nhau 2 d√≤ng\")\n",
    "    print(f\"   - C√≥ ƒë·∫ßy ƒë·ªß: Current + K + Transition Matrix\")\n",
    "    print(f\"\\nüéØ S·∫µn s√†ng g·ª≠i cho s·∫øp!\")\n",
    "    print(f\"{'='*60}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Kh√¥ng t√¨m th·∫•y cohorts\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
