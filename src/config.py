from pathlib import Path
import pandas as pd


# ===== Resolve project root from this file path (stable across notebooks/scripts) =====
PROJECT_ROOT = Path(__file__).resolve().parent.parent  # .../RR_model
OUT_ROOT     = PROJECT_ROOT / "outputs"

# Data source defaults to parquet for offline runs
DATA_SOURCE  = "parquet"  # options: "parquet" | "oracle"
PARQUET_DIR  = PROJECT_ROOT / "data" / "parquet"       # <-- FIXED: absolute path
PARQUET_FILE = None  # or "rollrate_base.parquet" if b·∫°n d√πng 1 file duy nh·∫•t

EXCEL_FILE   = PROJECT_ROOT / "data" / "rollrate_input.xlsx"   # üëà ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh n·∫øu d√πng Excel
EXCEL_SHEET  = "Data"    
# === COLUMNS CONFIG & others gi·ªØ nguy√™n ===

# ===========================
# A. Date Format Config
# ===========================
# N·∫øu DISBURSAL_DATE, CUTOFF_DATE l√† ƒë·ªãnh d·∫°ng YYYYMM (int ho·∫∑c string)
# th√¨ set DATE_FORMAT = "YYYYMM"
# N·∫øu l√† datetime th√¨ set DATE_FORMAT = "datetime"
DATE_FORMAT = "YYYYMM"  # "YYYYMM" ho·∫∑c "datetime"


def parse_date(value):
    """
    Parse date t·ª´ nhi·ªÅu ƒë·ªãnh d·∫°ng kh√°c nhau.
    - YYYYMM (int/string): 202501 -> 2025-01-01
    - datetime: gi·ªØ nguy√™n
    - string date: parse b√¨nh th∆∞·ªùng
    """
    if pd.isna(value):
        return pd.NaT
    
    # N·∫øu l√† int ho·∫∑c string d·∫°ng YYYYMM
    if isinstance(value, (int, float)):
        value = int(value)
        if 190001 <= value <= 209912:  # YYYYMM range
            year = value // 100
            month = value % 100
            return pd.Timestamp(year=year, month=month, day=1)
    
    # N·∫øu l√† string
    if isinstance(value, str):
        value = value.strip()
        # YYYYMM format
        if len(value) == 6 and value.isdigit():
            year = int(value[:4])
            month = int(value[4:6])
            return pd.Timestamp(year=year, month=month, day=1)
        # YYYY-MM format
        if len(value) == 7 and value[4] == '-':
            return pd.Timestamp(value + '-01')
    
    # Fallback: d√πng pd.to_datetime
    try:
        return pd.to_datetime(value)
    except:
        return pd.NaT


def parse_date_column(series):
    """Parse to√†n b·ªô column date."""
    return series.apply(parse_date)

# ===========================
# B. Model parameters
# ===========================
MIN_OBS = 100         # S·ªë quan s√°t t·ªëi thi·ªÉu
MIN_EAD = 1e2         # T·ªïng d∆∞ n·ª£ t·ªëi thi·ªÉu ƒë·ªÉ build transition
BUCKETS_30P = ["DPD30+", "DPD60+", "DPD90+", "DPD120+", "DPD180+", "WRITEOFF"]
BUCKETS_60P = ["DPD60+", "DPD90+", "DPD120+", "DPD180+", "WRITEOFF"]
BUCKETS_90P = ["DPD90+", "DPD120+", "DPD180+", "WRITEOFF"]
# === COLUMNS CONFIG ===
CFG = dict(
    loan="AGREEMENT_ID",
    mob="MOB",
    state="STATE_MODEL",
    orig_date="DISBURSAL_DATE",
    ead="PRINCIPLE_OUTSTANDING",
    disb="DISBURSAL_AMOUNT",
    cutoff="CUTOFF_DATE",
)

# === SEGMENTATION CONFIG ===
# C√°c c·ªôt d√πng ƒë·ªÉ ph√¢n nh√≥m (segment) khi t√≠nh transition matrix v√† forecast
# Thay ƒë·ªïi list n√†y ƒë·ªÉ th√™m/b·ªõt segment dimensions
# L∆∞u √Ω: Code s·ª≠ d·ª•ng 2 c·ªôt c·ªë ƒë·ªãnh: PRODUCT_TYPE v√† RISK_SCORE
# - PRODUCT_TYPE: gi·ªØ nguy√™n t·ª´ data
# - RISK_SCORE: s·∫Ω ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ c√°c c·ªôt trong SEGMENT_COLS (tr·ª´ PRODUCT_TYPE)
#
# V√≠ d·ª•:
# - SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE"] => gi·ªØ nguy√™n RISK_SCORE t·ª´ data
# - SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE", "GENDER"] => RISK_SCORE = "RISK_SCORE_GENDER"
# - SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE", "GENDER", "LA_GROUP"] => RISK_SCORE = "RISK_SCORE_GENDER_LA_GROUP"
SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE","GENDER","LA_GROUP","SALE_CHANNEL"]  # M·∫∑c ƒë·ªãnh: gi·ªØ nguy√™n RISK_SCORE t·ª´ data

def get_cohort_cols():
    """Tr·∫£ v·ªÅ list columns ƒë·ªÉ ƒë·ªãnh nghƒ©a 1 cohort: SEGMENT_COLS + VINTAGE_DATE"""
    return ["PRODUCT_TYPE", "RISK_SCORE", "VINTAGE_DATE"]

def get_cohort_mob_cols():
    """Tr·∫£ v·ªÅ list columns ƒë·ªÉ ƒë·ªãnh nghƒ©a 1 cohort t·∫°i 1 MOB"""
    return ["PRODUCT_TYPE", "RISK_SCORE", "VINTAGE_DATE", "MOB"]

def create_segment_columns(df):
    """
    T·∫°o c·ªôt PRODUCT_TYPE v√† RISK_SCORE t·ª´ SEGMENT_COLS.
    
    Logic:
    - N·∫øu SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE"]: gi·ªØ nguy√™n
    - N·∫øu SEGMENT_COLS = ["PRODUCT_TYPE", "GRADE", "GENDER", "LA_GROUP"]:
      + PRODUCT_TYPE: gi·ªØ nguy√™n
      + RISK_SCORE = "GRADE_GENDER_LA_GROUP" (gh√©p c√°c gi√° tr·ªã)
    
    Returns:
        DataFrame v·ªõi c·ªôt PRODUCT_TYPE v√† RISK_SCORE ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a
    """
    df = df.copy()
    
    # L·∫•y c√°c c·ªôt segment (tr·ª´ PRODUCT_TYPE)
    other_cols = [c for c in SEGMENT_COLS if c != "PRODUCT_TYPE"]
    
    if not other_cols:
        # Kh√¥ng c√≥ c·ªôt n√†o kh√°c, t·∫°o RISK_SCORE m·∫∑c ƒë·ªãnh
        if "RISK_SCORE" not in df.columns:
            df["RISK_SCORE"] = "ALL"
    elif other_cols == ["RISK_SCORE"]:
        # Ch·ªâ c√≥ RISK_SCORE, gi·ªØ nguy√™n
        df["RISK_SCORE"] = df["RISK_SCORE"].astype(str)
    else:
        # Gh√©p nhi·ªÅu c·ªôt th√†nh RISK_SCORE
        # Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng
        missing_cols = [c for c in other_cols if c not in df.columns]
        if missing_cols:
            raise KeyError(f"SEGMENT_COLS ch·ª©a c√°c c·ªôt kh√¥ng t·ªìn t·∫°i trong data: {missing_cols}")
        
        # Gh√©p c√°c c·ªôt th√†nh RISK_SCORE
        df["RISK_SCORE"] = df[other_cols].astype(str).agg("_".join, axis=1)
        print(f"   ‚úÖ T·∫°o RISK_SCORE t·ª´ {other_cols}: {df['RISK_SCORE'].nunique()} unique values")
    
    # ƒê·∫£m b·∫£o PRODUCT_TYPE l√† string
    if "PRODUCT_TYPE" in df.columns:
        df["PRODUCT_TYPE"] = df["PRODUCT_TYPE"].astype(str)
    
    return df

SEGMENT_MAP = {
    "RISK_SCORE": ["LOW", "MEDIUM", "HIGH"],
    "PRODUCT_TYPE": ["PL", "CC"],
}


# === SMOOTHING CONFIG ===
ALPHA_SMOOTH = 0.5

# === STATE DEFINITIONS ===
BUCKETS_CANON = [
    "DPD0", "DPD1+", "DPD30+", "DPD60+", "DPD90+", "DPD120+", "DPD180+",
    "PREPAY", "WRITEOFF", "SOLDOUT"
]

#ABSORBING_BASE = ["WRITEOFF", "PREPAY", "SOLDOUT"]
ABSORBING_BASE = ["DPD90+", "WRITEOFF", "PREPAY", "SOLDOUT"] # PD model

DEFAULT = {"DPD90+"}

# === MODEL CONFIG ===
WEIGHT_METHOD = "exp"
#WEIGHT_METHOD = None
ROLL_WINDOW = 20
CFG["ROLL_WINDOW"] = ROLL_WINDOW
DECAY_LAMBDA = 0.5 ** (1/20)
CFG["DECAY_LAMBDA"] = DECAY_LAMBDA
# === MACRO & COLLX ADJUSTMENT CONFIG (optional, not wired by default) ===
MACRO_INDICATORS = {
    "GDP_GROWTH": {"weight": -0.3},
    "UNEMPLOYMENT_RATE": {"weight": +0.5},
    "CPI": {"weight": +0.2},
    "POLICY_RATE": {"weight": +0.3},
}
COLLX_CONFIG = {
    "COLLX_INDEX": {
        "weight": -0.4,
        "ref_value": 1.0,
        "min_adj": -0.3,
        "max_adj": +0.3,
    }
}
ADJUST_METHOD = "multiplicative"
MACRO_LAG = 1
MACRO_SOURCE = "sql/macro_data.sql"
COLLX_SOURCE = "sql/collx_index.sql"


# ===========================
# C. Excel Export Helper
# ===========================
EXCEL_MAX_ROWS = 1_000_000  # Excel limit is 1,048,576, use 1M for safety


def export_large_dataframe(df, filepath, sheet_prefix="Data", index=False):
    """
    Export DataFrame l·ªõn ra Excel, t·ª± ƒë·ªông chia th√†nh nhi·ªÅu sheet n·∫øu v∆∞·ª£t qu√° gi·ªõi h·∫°n.
    
    Args:
        df: DataFrame c·∫ßn export
        filepath: ƒê∆∞·ªùng d·∫´n file Excel (str ho·∫∑c Path)
        sheet_prefix: T√™n prefix cho sheet (m·∫∑c ƒë·ªãnh "Data")
        index: C√≥ ghi index kh√¥ng (m·∫∑c ƒë·ªãnh False)
    
    Returns:
        int: S·ªë sheet ƒë√£ t·∫°o
    
    Example:
        export_large_dataframe(df_loan_forecast, "outputs/Loan_Forecast.xlsx", "Loans")
        # N·∫øu df c√≥ 2.5M rows -> t·∫°o 3 sheets: Loans_1, Loans_2, Loans_3
    """
    filepath = Path(filepath)
    n_rows = len(df)
    
    if n_rows <= EXCEL_MAX_ROWS:
        # ƒê·ªß nh·ªè, ghi 1 sheet
        df.to_excel(filepath, sheet_name=sheet_prefix, index=index, engine="xlsxwriter")
        print(f"   ‚úÖ Exported {n_rows:,} rows to {filepath}")
        return 1
    
    # C·∫ßn chia nhi·ªÅu sheet
    n_sheets = (n_rows // EXCEL_MAX_ROWS) + 1
    print(f"   ‚ö†Ô∏è Data c√≥ {n_rows:,} rows > {EXCEL_MAX_ROWS:,} limit")
    print(f"   üìä Chia th√†nh {n_sheets} sheets...")
    
    with pd.ExcelWriter(filepath, engine="xlsxwriter") as writer:
        for i in range(n_sheets):
            start_idx = i * EXCEL_MAX_ROWS
            end_idx = min((i + 1) * EXCEL_MAX_ROWS, n_rows)
            
            sheet_name = f"{sheet_prefix}_{i+1}"
            df_chunk = df.iloc[start_idx:end_idx]
            df_chunk.to_excel(writer, sheet_name=sheet_name, index=index)
            
            print(f"      Sheet {sheet_name}: rows {start_idx:,} ‚Üí {end_idx:,} ({len(df_chunk):,} rows)")
    
    print(f"   ‚úÖ Exported {n_rows:,} rows to {filepath} ({n_sheets} sheets)")
    return n_sheets


def export_loan_forecast_excel(df, filepath, target_mobs=None, include_del_sheets=True):
    """
    Export loan forecast ra Excel v·ªõi nhi·ªÅu sheets.
    T·ª± ƒë·ªông chia nh·ªè n·∫øu data qu√° l·ªõn.
    
    Args:
        df: DataFrame loan forecast
        filepath: ƒê∆∞·ªùng d·∫´n file Excel
        target_mobs: List MOBs (vd: [12, 24]) ƒë·ªÉ t·∫°o sheet DEL ri√™ng
        include_del_sheets: C√≥ t·∫°o sheet ri√™ng cho DEL90 kh√¥ng
    
    Example:
        export_loan_forecast_excel(
            df_loan_forecast, 
            "outputs/Loan_Forecast.xlsx",
            target_mobs=[12, 24],
            include_del_sheets=True
        )
    """
    filepath = Path(filepath)
    n_rows = len(df)
    
    if n_rows <= EXCEL_MAX_ROWS:
        # ƒê·ªß nh·ªè, ghi b√¨nh th∆∞·ªùng v·ªõi nhi·ªÅu sheets
        with pd.ExcelWriter(filepath, engine="xlsxwriter") as writer:
            df.to_excel(writer, sheet_name="All_Loans", index=False)
            
            if include_del_sheets and target_mobs:
                for mob in target_mobs:
                    col = f'DEL90_FLAG_MOB{mob}'
                    if col in df.columns:
                        df_del = df[df[col] == 1]
                        if len(df_del) > 0:
                            df_del.to_excel(writer, sheet_name=f"DEL90_MOB{mob}", index=False)
        
        print(f"   ‚úÖ Exported {n_rows:,} rows to {filepath}")
        return
    
    # Data qu√° l·ªõn, c·∫ßn chia nh·ªè
    print(f"   ‚ö†Ô∏è Data c√≥ {n_rows:,} rows > {EXCEL_MAX_ROWS:,} limit")
    
    n_sheets = (n_rows // EXCEL_MAX_ROWS) + 1
    print(f"   üìä Chia All_Loans th√†nh {n_sheets} sheets...")
    
    with pd.ExcelWriter(filepath, engine="xlsxwriter") as writer:
        # Chia All_Loans th√†nh nhi·ªÅu sheets
        for i in range(n_sheets):
            start_idx = i * EXCEL_MAX_ROWS
            end_idx = min((i + 1) * EXCEL_MAX_ROWS, n_rows)
            
            sheet_name = f"All_Loans_{i+1}" if n_sheets > 1 else "All_Loans"
            df_chunk = df.iloc[start_idx:end_idx]
            df_chunk.to_excel(writer, sheet_name=sheet_name, index=False)
            print(f"      {sheet_name}: {len(df_chunk):,} rows")
        
        # DEL sheets (th∆∞·ªùng nh·ªè h∆°n nhi·ªÅu)
        if include_del_sheets and target_mobs:
            for mob in target_mobs:
                col = f'DEL90_FLAG_MOB{mob}'
                if col in df.columns:
                    df_del = df[df[col] == 1]
                    if len(df_del) > 0:
                        if len(df_del) <= EXCEL_MAX_ROWS:
                            df_del.to_excel(writer, sheet_name=f"DEL90_MOB{mob}", index=False)
                            print(f"      DEL90_MOB{mob}: {len(df_del):,} rows")
                        else:
                            # DEL c≈©ng qu√° l·ªõn, chia nh·ªè
                            n_del_sheets = (len(df_del) // EXCEL_MAX_ROWS) + 1
                            for j in range(n_del_sheets):
                                s = j * EXCEL_MAX_ROWS
                                e = min((j + 1) * EXCEL_MAX_ROWS, len(df_del))
                                df_del.iloc[s:e].to_excel(
                                    writer, 
                                    sheet_name=f"DEL90_MOB{mob}_{j+1}", 
                                    index=False
                                )
    
    print(f"   ‚úÖ Exported {n_rows:,} rows to {filepath}")
