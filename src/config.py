from pathlib import Path
import pandas as pd


# ===== Resolve project root from this file path (stable across notebooks/scripts) =====
PROJECT_ROOT = Path(__file__).resolve().parent.parent  # .../RR_model
OUT_ROOT     = PROJECT_ROOT / "outputs"

# Data source defaults to parquet for offline runs
DATA_SOURCE  = "parquet"  # options: "parquet" | "oracle"
PARQUET_DIR  = PROJECT_ROOT / "data" / "parquet"       # <-- FIXED: absolute path
PARQUET_FILE = None  # or "rollrate_base.parquet" if b·∫°n d√πng 1 file duy nh·∫•t

EXCEL_FILE   = PROJECT_ROOT / "data" / "rollrate_input.xlsx"   # üëà ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh n·∫øu d√πng Excel
EXCEL_SHEET  = "Data"    
# === COLUMNS CONFIG & others gi·ªØ nguy√™n ===

# ===========================
# A. Date Format Config
# ===========================
# N·∫øu DISBURSAL_DATE, CUTOFF_DATE l√† ƒë·ªãnh d·∫°ng YYYYMM (int ho·∫∑c string)
# th√¨ set DATE_FORMAT = "YYYYMM"
# N·∫øu l√† datetime th√¨ set DATE_FORMAT = "datetime"
DATE_FORMAT = "YYYYMM"  # "YYYYMM" ho·∫∑c "datetime"


def parse_date(value):
    """
    Parse date t·ª´ nhi·ªÅu ƒë·ªãnh d·∫°ng kh√°c nhau.
    - YYYYMM (int/string): 202501 -> 2025-01-01
    - datetime: gi·ªØ nguy√™n
    - string date: parse b√¨nh th∆∞·ªùng
    """
    if pd.isna(value):
        return pd.NaT
    
    # N·∫øu l√† int ho·∫∑c string d·∫°ng YYYYMM
    if isinstance(value, (int, float)):
        value = int(value)
        if 190001 <= value <= 209912:  # YYYYMM range
            year = value // 100
            month = value % 100
            return pd.Timestamp(year=year, month=month, day=1)
    
    # N·∫øu l√† string
    if isinstance(value, str):
        value = value.strip()
        # YYYYMM format
        if len(value) == 6 and value.isdigit():
            year = int(value[:4])
            month = int(value[4:6])
            return pd.Timestamp(year=year, month=month, day=1)
        # YYYY-MM format
        if len(value) == 7 and value[4] == '-':
            return pd.Timestamp(value + '-01')
    
    # Fallback: d√πng pd.to_datetime
    try:
        return pd.to_datetime(value)
    except:
        return pd.NaT


def parse_date_column(series):
    """Parse to√†n b·ªô column date."""
    return series.apply(parse_date)

# ===========================
# B. Model parameters
# ===========================
MIN_OBS = 100         # S·ªë quan s√°t t·ªëi thi·ªÉu
MIN_EAD = 1e2         # T·ªïng d∆∞ n·ª£ t·ªëi thi·ªÉu ƒë·ªÉ build transition
BUCKETS_30P = ["DPD30+", "DPD60+", "DPD90+", "DPD120+", "DPD180+", "WRITEOFF"]
BUCKETS_60P = ["DPD60+", "DPD90+", "DPD120+", "DPD180+", "WRITEOFF"]
BUCKETS_90P = ["DPD90+", "DPD120+", "DPD180+", "WRITEOFF"]
# === COLUMNS CONFIG ===
CFG = dict(
    loan="AGREEMENT_ID",
    mob="MOB",
    state="STATE_MODEL",
    orig_date="DISBURSAL_DATE",
    ead="PRINCIPLE_OUTSTANDING",
    disb="DISBURSAL_AMOUNT",
    cutoff="CUTOFF_DATE",
)

# === SEGMENTATION CONFIG ===
# C√°c c·ªôt d√πng ƒë·ªÉ ph√¢n nh√≥m (segment) khi t√≠nh transition matrix v√† forecast
# Thay ƒë·ªïi list n√†y ƒë·ªÉ th√™m/b·ªõt segment dimensions
# L∆∞u √Ω: Code s·ª≠ d·ª•ng 2 c·ªôt c·ªë ƒë·ªãnh: PRODUCT_TYPE v√† RISK_SCORE
# - PRODUCT_TYPE: gi·ªØ nguy√™n t·ª´ data
# - RISK_SCORE: s·∫Ω ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ c√°c c·ªôt trong SEGMENT_COLS (tr·ª´ PRODUCT_TYPE)
#
# V√≠ d·ª•:
# - SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE"] => gi·ªØ nguy√™n RISK_SCORE t·ª´ data
# - SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE", "GENDER"] => RISK_SCORE = "RISK_SCORE_GENDER"
# - SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE", "GENDER", "LA_GROUP"] => RISK_SCORE = "RISK_SCORE_GENDER_LA_GROUP"
SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE"]  # M·∫∑c ƒë·ªãnh: gi·ªØ nguy√™n RISK_SCORE t·ª´ data

def get_cohort_cols():
    """Tr·∫£ v·ªÅ list columns ƒë·ªÉ ƒë·ªãnh nghƒ©a 1 cohort: SEGMENT_COLS + VINTAGE_DATE"""
    return ["PRODUCT_TYPE", "RISK_SCORE", "VINTAGE_DATE"]

def get_cohort_mob_cols():
    """Tr·∫£ v·ªÅ list columns ƒë·ªÉ ƒë·ªãnh nghƒ©a 1 cohort t·∫°i 1 MOB"""
    return ["PRODUCT_TYPE", "RISK_SCORE", "VINTAGE_DATE", "MOB"]

def create_segment_columns(df):
    """
    T·∫°o c·ªôt PRODUCT_TYPE v√† RISK_SCORE t·ª´ SEGMENT_COLS.
    
    Logic:
    - N·∫øu SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE"]: gi·ªØ nguy√™n
    - N·∫øu SEGMENT_COLS = ["PRODUCT_TYPE", "GRADE", "GENDER", "LA_GROUP"]:
      + PRODUCT_TYPE: gi·ªØ nguy√™n
      + RISK_SCORE = "GRADE_GENDER_LA_GROUP" (gh√©p c√°c gi√° tr·ªã)
    
    Returns:
        DataFrame v·ªõi c·ªôt PRODUCT_TYPE v√† RISK_SCORE ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a
    """
    df = df.copy()
    
    # L·∫•y c√°c c·ªôt segment (tr·ª´ PRODUCT_TYPE)
    other_cols = [c for c in SEGMENT_COLS if c != "PRODUCT_TYPE"]
    
    if not other_cols:
        # Kh√¥ng c√≥ c·ªôt n√†o kh√°c, t·∫°o RISK_SCORE m·∫∑c ƒë·ªãnh
        if "RISK_SCORE" not in df.columns:
            df["RISK_SCORE"] = "ALL"
    elif other_cols == ["RISK_SCORE"]:
        # Ch·ªâ c√≥ RISK_SCORE, gi·ªØ nguy√™n
        df["RISK_SCORE"] = df["RISK_SCORE"].astype(str)
    else:
        # Gh√©p nhi·ªÅu c·ªôt th√†nh RISK_SCORE
        # Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng
        missing_cols = [c for c in other_cols if c not in df.columns]
        if missing_cols:
            raise KeyError(f"SEGMENT_COLS ch·ª©a c√°c c·ªôt kh√¥ng t·ªìn t·∫°i trong data: {missing_cols}")
        
        # Gh√©p c√°c c·ªôt th√†nh RISK_SCORE
        df["RISK_SCORE"] = df[other_cols].astype(str).agg("_".join, axis=1)
        print(f"   ‚úÖ T·∫°o RISK_SCORE t·ª´ {other_cols}: {df['RISK_SCORE'].nunique()} unique values")
    
    # ƒê·∫£m b·∫£o PRODUCT_TYPE l√† string
    if "PRODUCT_TYPE" in df.columns:
        df["PRODUCT_TYPE"] = df["PRODUCT_TYPE"].astype(str)
    
    return df

SEGMENT_MAP = {
    "RISK_SCORE": ["LOW", "MEDIUM", "HIGH"],
    "PRODUCT_TYPE": ["PL", "CC"],
}


# === SMOOTHING CONFIG ===
ALPHA_SMOOTH = 0.5

# === STATE DEFINITIONS ===
BUCKETS_CANON = [
    "DPD0", "DPD1+", "DPD30+", "DPD60+", "DPD90+", "DPD120+", "DPD180+",
    "PREPAY", "WRITEOFF", "SOLDOUT"
]

#ABSORBING_BASE = ["WRITEOFF", "PREPAY", "SOLDOUT"]
ABSORBING_BASE = ["DPD90+", "WRITEOFF", "PREPAY", "SOLDOUT"] # PD model

DEFAULT = {"DPD90+"}

# === MODEL CONFIG ===
WEIGHT_METHOD = "exp"
#WEIGHT_METHOD = None
ROLL_WINDOW = 20
CFG["ROLL_WINDOW"] = ROLL_WINDOW
DECAY_LAMBDA = 0.5 ** (1/20)
CFG["DECAY_LAMBDA"] = DECAY_LAMBDA
# === MACRO & COLLX ADJUSTMENT CONFIG (optional, not wired by default) ===
MACRO_INDICATORS = {
    "GDP_GROWTH": {"weight": -0.3},
    "UNEMPLOYMENT_RATE": {"weight": +0.5},
    "CPI": {"weight": +0.2},
    "POLICY_RATE": {"weight": +0.3},
}
COLLX_CONFIG = {
    "COLLX_INDEX": {
        "weight": -0.4,
        "ref_value": 1.0,
        "min_adj": -0.3,
        "max_adj": +0.3,
    }
}
ADJUST_METHOD = "multiplicative"
MACRO_LAG = 1
MACRO_SOURCE = "sql/macro_data.sql"
COLLX_SOURCE = "sql/collx_index.sql"
