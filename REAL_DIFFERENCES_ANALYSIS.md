# Ph√¢n T√≠ch S·ª± Kh√°c Bi·ªát TH·ª∞C S·ª∞

## ‚úÖ X√°c Nh·∫≠n: C·∫£ 2 ƒê·ªÅu D√πng CHUNG Logic

Sau khi ki·ªÉm tra k·ªπ, **C·∫¢ 2 notebooks ƒë·ªÅu s·ª≠ d·ª•ng CHUNG c√°c functions** t·ª´:
- `src.rollrate.calibration_kmob`
- `src.rollrate.lifecycle`
- `src.rollrate.transition`

**KH√îNG c√≥ logic ri√™ng** ƒë∆∞·ª£c define trong notebooks.

---

## üîç S·ª± Kh√°c Bi·ªát TH·ª∞C S·ª∞

### 1Ô∏è‚É£ RISK_SCORE Definition ‚ö†Ô∏è CRITICAL

#### Projection_done
```python
df_raw["RISK_SCORE"] = df_raw["GRADE"].astype(str)
```
- RISK_SCORE = GRADE (1 c·ªôt duy nh·∫•t)
- V√≠ d·ª•: "A", "B", "C", "D"
- S·ªë l∆∞·ª£ng segments: √çt (v√†i ch·ª•c)

#### Final_Workflow
```python
df_raw = create_segment_columns(df_raw)
```

V·ªõi `SEGMENT_COLS` trong `src/config.py`:
```python
SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE"]
# Ho·∫∑c c√≥ th·ªÉ l√†:
# SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE", "GENDER", "LA_GROUP", "SALE_CHANNEL"]
```

N·∫øu `SEGMENT_COLS = ["PRODUCT_TYPE", "RISK_SCORE", "GENDER", "LA_GROUP", "SALE_CHANNEL"]`:
```python
# RISK_SCORE ƒë∆∞·ª£c t·∫°o t·ª´ nhi·ªÅu c·ªôt:
df["RISK_SCORE"] = df[["RISK_SCORE", "GENDER", "LA_GROUP", "SALE_CHANNEL"]].agg("_".join, axis=1)
# V√≠ d·ª•: "650+_F_15M-_POS", "500-_M_10M-_Direct Sale"
```

**Impact**: ‚ö†Ô∏è **CRITICAL**
- S·ªë l∆∞·ª£ng segments kh√°c nhau ho√†n to√†n
- Projection_done: ~10-20 segments (ch·ªâ GRADE)
- Final_Workflow: ~130 segments (GRADE √ó GENDER √ó LA_GROUP √ó SALE_CHANNEL)
- ‚Üí Transition matrices kh√°c nhau
- ‚Üí K values kh√°c nhau
- ‚Üí Forecast kh√°c nhau

---

### 2Ô∏è‚É£ MAX_MOB

#### Projection_done
```python
max_mob = 36
```

#### Final_Workflow
```python
MAX_MOB = 13
```

**Impact**: ‚ö†Ô∏è HIGH
- Forecast horizon kh√°c nhau

---

### 3Ô∏è‚É£ Regularization

#### Projection_done
```python
LAMBDA_K = 1e-4
K_PRIOR = 0.0

k_raw_by_mob = fit_k_raw(
    ...,
    method="wls_reg",
    lambda_k=LAMBDA_K,
    k_prior=K_PRIOR,
)
```

#### Final_Workflow
```python
k_raw_by_mob = fit_k_raw(
    ...,
    # No regularization parameters
)
```

**Impact**: ‚ö†Ô∏è HIGH
- K values kh√°c nhau

---

### 4Ô∏è‚É£ Data Source

#### Projection_done
```python
# From output log:
# üì¶ Loading Parquet from: C:\Users\User\Projection_kiro\ETB_Parquet
# ‚úÖ Loaded 6,065,817 rows
```

#### Final_Workflow
```python
DATA_PATH = 'C:/Users/User/Projection_PB/Projection_pb/POS_Parquet_YYYYMM'
# From output log:
# ‚úÖ Loaded 19,279,033 rows
```

**Impact**: ‚ö†Ô∏è **CRITICAL**
- Data source kh√°c nhau!
- ETB_Parquet vs POS_Parquet_YYYYMM
- 6M rows vs 19M rows
- ‚Üí Ho√†n to√†n kh√°c data!

---

## üìä B·∫£ng T·ªïng H·ª£p

| Aspect | Projection_done | Final_Workflow | Impact |
|--------|-----------------|----------------|--------|
| **Data Source** | ETB_Parquet (6M rows) | POS_Parquet_YYYYMM (19M rows) | **CRITICAL** |
| **RISK_SCORE** | GRADE only | GRADE_GENDER_LA_GROUP_SALE_CHANNEL | **CRITICAL** |
| **Segments** | ~10-20 | ~130 | **CRITICAL** |
| **MAX_MOB** | 36 | 13 | HIGH |
| **Regularization** | Yes | No | HIGH |
| **Logic Functions** | ‚úÖ SAME | ‚úÖ SAME | N/A |

---

## üéØ Nguy√™n Nh√¢n G·ªëc R·ªÖ

### T·∫°i Sao K·∫øt Qu·∫£ Kh√°c Nhau?

**3 nguy√™n nh√¢n CH√çNH**:

1. **Data Source Kh√°c Nhau** ‚ö†Ô∏è CRITICAL
   - ETB_Parquet vs POS_Parquet_YYYYMM
   - 6M rows vs 19M rows
   - ‚Üí Ho√†n to√†n kh√°c data!

2. **RISK_SCORE Definition Kh√°c Nhau** ‚ö†Ô∏è CRITICAL
   - Projection_done: GRADE only (~10-20 values)
   - Final_Workflow: GRADE √ó GENDER √ó LA_GROUP √ó SALE_CHANNEL (~130 values)
   - ‚Üí Segmentation kh√°c nhau ho√†n to√†n
   - ‚Üí Transition matrices kh√°c nhau
   - ‚Üí K values kh√°c nhau

3. **Config Parameters Kh√°c Nhau** ‚ö†Ô∏è HIGH
   - MAX_MOB: 36 vs 13
   - Regularization: Yes vs No

### Chu·ªói ·∫¢nh H∆∞·ªüng

```
Data Source kh√°c (ETB vs POS)
    ‚Üì
RISK_SCORE definition kh√°c (GRADE vs GRADE_GENDER_LA_GROUP_SALE_CHANNEL)
    ‚Üì
S·ªë l∆∞·ª£ng segments kh√°c (20 vs 130)
    ‚Üì
Transition matrices kh√°c
    ‚Üì
fit_k_raw v·ªõi data kh√°c + regularization kh√°c
    ‚Üì
K values kh√°c
    ‚Üì
smooth_k v·ªõi K kh√°c
    ‚Üì
fit_alpha v·ªõi mob_target kh√°c (36 vs 13)
    ‚Üì
k_final kh√°c
    ‚Üì
forecast_all_vintages_partial_step v·ªõi max_mob kh√°c (36 vs 13)
    ‚Üì
FORECAST RESULTS HO√ÄN TO√ÄN KH√ÅC NHAU ‚úÖ
```

---

## ‚úÖ K·∫øt Lu·∫≠n

### Logic T√≠nh To√°n

**‚úÖ C·∫¢ 2 NOTEBOOKS D√ôNG CHUNG LOGIC**

T·∫•t c·∫£ functions ƒë·ªÅu t·ª´:
- `src.rollrate.calibration_kmob.fit_k_raw`
- `src.rollrate.calibration_kmob.smooth_k`
- `src.rollrate.calibration_kmob.fit_alpha`
- `src.rollrate.calibration_kmob.forecast_all_vintages_partial_step`
- `src.rollrate.lifecycle.get_actual_all_vintages_amount`
- `src.rollrate.lifecycle.combine_all_lifecycle_amount`
- `src.rollrate.transition.compute_transition_by_mob`

**KH√îNG c√≥ logic ri√™ng** trong notebooks.

### T·∫°i Sao K·∫øt Qu·∫£ Kh√°c?

**KH√îNG PH·∫¢I do logic kh√°c nhau**, m√† do:

1. **Data source kh√°c nhau** (ETB vs POS)
2. **RISK_SCORE definition kh√°c nhau** (GRADE vs GRADE_GENDER_LA_GROUP_SALE_CHANNEL)
3. **Config parameters kh√°c nhau** (MAX_MOB, regularization)

### C√≥ Th·ªÉ So S√°nh ƒê∆∞·ª£c Kh√¥ng?

**KH√îNG** - V√¨:
- Data source kh√°c nhau ‚Üí Kh√¥ng th·ªÉ so s√°nh tr·ª±c ti·∫øp
- Segmentation kh√°c nhau ‚Üí Kh√¥ng th·ªÉ so s√°nh tr·ª±c ti·∫øp
- M·ª•c ƒë√≠ch kh√°c nhau ‚Üí Kh√¥ng n√™n so s√°nh

### C·∫£ Hai ƒê·ªÅu ƒê√∫ng?

**‚úÖ C·∫¢ HAI ƒê·ªÄU ƒê√öNG**

- Projection_done: ƒê√∫ng cho ETB data v·ªõi GRADE segmentation
- Final_Workflow: ƒê√∫ng cho POS data v·ªõi fine-grained segmentation

---

## üí° Khuy·∫øn Ngh·ªã

### Option 1: Gi·ªØ Nguy√™n ‚úÖ RECOMMENDED

**L√Ω do**:
- Hai notebooks ph·ª•c v·ª• data sources kh√°c nhau
- Segmentation strategies kh√°c nhau
- C·∫£ hai ƒë·ªÅu valid cho use case ri√™ng

**Action**: Kh√¥ng c·∫ßn thay ƒë·ªïi

### Option 2: Standardize (N·∫øu C·∫ßn)

N·∫øu mu·ªën so s√°nh tr·ª±c ti·∫øp, c·∫ßn:

1. **D√πng c√πng data source**
   ```python
   # C·∫£ 2 notebooks d√πng c√πng:
   DATA_PATH = 'C:/Users/User/Projection_PB/Projection_pb/POS_Parquet_YYYYMM'
   ```

2. **D√πng c√πng RISK_SCORE definition**
   ```python
   # Projection_done:
   df_raw = create_segment_columns(df_raw)  # Thay v√¨ df_raw["RISK_SCORE"] = df_raw["GRADE"]
   ```

3. **D√πng c√πng config**
   ```python
   # Projection_done:
   max_mob = 13  # Thay v√¨ 36
   # B·ªè regularization
   ```

**L∆∞u √Ω**: ƒêi·ªÅu n√†y s·∫Ω l√†m m·∫•t ƒëi m·ª•c ƒë√≠ch ri√™ng c·ªßa m·ªói notebook

### Option 3: Document Clearly

Th√™m comment r√µ r√†ng v√†o ƒë·∫ßu m·ªói notebook:

#### Projection_done
```python
"""
ETB Data Analysis Notebook
- Data: ETB_Parquet (6M rows)
- Segmentation: GRADE only (~20 segments)
- Horizon: 36 months (long-term)
- Approach: Conservative with regularization
"""
```

#### Final_Workflow
```python
"""
POS Data Operational Workflow
- Data: POS_Parquet_YYYYMM (19M rows)
- Segmentation: GRADE √ó GENDER √ó LA_GROUP √ó SALE_CHANNEL (~130 segments)
- Horizon: 13 months (short-term)
- Approach: Straightforward without regularization
"""
```

---

## üß™ Verification

### Test 1: Check Data Source
```python
# In both notebooks:
print(f"Data path: {DATA_PATH}")
print(f"Rows: {len(df_raw):,}")
print(f"Columns: {df_raw.columns.tolist()}")
```

### Test 2: Check RISK_SCORE
```python
# In both notebooks:
print(f"RISK_SCORE unique values: {df_raw['RISK_SCORE'].nunique()}")
print(f"Sample values: {df_raw['RISK_SCORE'].unique()[:5]}")
```

### Test 3: Check Segments
```python
# In both notebooks:
segments = df_raw.groupby(['PRODUCT_TYPE', 'RISK_SCORE']).size()
print(f"Total segments: {len(segments)}")
print(f"Top 5 segments:\n{segments.head()}")
```

---

## üìö Files Li√™n Quan

- `compare_notebooks_logic.py` - Script so s√°nh
- `src/config.py` - SEGMENT_COLS definition
- `src/rollrate/calibration_kmob.py` - Shared logic
- `src/rollrate/lifecycle.py` - Shared logic

---

**Date**: 2026-01-17  
**Status**: ‚úÖ Thoroughly Analyzed  
**Conclusion**: Same logic, different data & config
