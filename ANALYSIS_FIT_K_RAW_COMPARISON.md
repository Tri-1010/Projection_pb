# Ph√¢n T√≠ch Chi Ti·∫øt: fit_k_raw - Projection_done vs Final_Workflow

## üìä So S√°nh Parameters

### Projection_done

#### Version 1: WLS (Baseline)
```python
k_raw_by_mob, weight_by_mob, k_raw_df = fit_k_raw(
    actual_results=actual_results_fit,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    states=states,
    s30_states=s30_states,
    include_co=True,
    denom_mode="disb",                    # ‚Üê D√πng DISB l√†m denominator
    disb_total_by_vintage=disb_total_by_vintage_fit,
    min_disb=1e-10,
    weight_mode="equal",                  # ‚Üê Equal weight cho m·ªçi vintage
    method="wls",                         # ‚Üê Weighted Least Squares
    eps=1e-8,
    min_denom=1e-10,
    min_obs=5,
    fallback_k=1.0,
    fallback_weight=0.0,
    return_detail=True,
)
```

#### Version 2: WLS with Regularization
```python
LAMBDA_K = 1e-4
K_PRIOR = 0.0

k_raw_reg_by_mob, weight_reg_by_mob, k_raw_reg_df = fit_k_raw(
    actual_results=actual_results_fit,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    states=states,
    s30_states=s30_states,
    include_co=True,
    denom_mode="disb",
    disb_total_by_vintage=disb_total_by_vintage_fit,
    min_disb=1e-10,
    weight_mode="equal",
    method="wls_reg",                     # ‚Üê Regularized WLS
    lambda_k=LAMBDA_K,                    # ‚Üê Regularization strength = 1e-4
    k_prior=K_PRIOR,                      # ‚Üê Prior value = 0.0
    eps=1e-8,
    min_denom=1e-10,
    min_obs=5,
    fallback_k=1.0,
    fallback_weight=0.0,
    return_detail=True,
)
```

### Final_Workflow

```python
k_raw_by_mob, weight_by_mob, _ = fit_k_raw(
    actual_results=actual_results,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    states=BUCKETS_CANON,
    s30_states=BUCKETS_30P,
    include_co=True,
    denom_mode="disb",                    # ‚Üê D√πng DISB l√†m denominator
    disb_total_by_vintage=disb_total_by_vintage,
    return_detail=True,
    # Kh√¥ng c√≥: weight_mode, method, lambda_k, k_prior
    # ‚Üí S·ª≠ d·ª•ng defaults
)
```

**Defaults** (t·ª´ function signature):
```python
method="ratio"           # ‚Üê Default method
weight_mode="ead"        # ‚Üê Default weight mode
lambda_k=0.0            # ‚Üê No regularization
k_prior=0.0
```

---

## üîç S·ª± Kh√°c Bi·ªát Quan Tr·ªçng

### 1. Method ‚ö†Ô∏è CRITICAL

| Notebook | Method | Formula |
|----------|--------|---------|
| **Projection_done (v1)** | `wls` | `k_m = Œ£(w¬∑a¬∑d) / Œ£(w¬∑a¬≤)` |
| **Projection_done (v2)** | `wls_reg` | `k_m = [Œ£(w¬∑a¬∑d) + Œª¬∑k_prior] / [Œ£(w¬∑a¬≤) + Œª]` |
| **Final_Workflow** | `ratio` (default) | `k = d/a` per vintage, then aggregate |

**Impact**: ‚ö†Ô∏è **CRITICAL**
- `ratio`: T√≠nh k cho t·ª´ng vintage ri√™ng l·∫ª, sau ƒë√≥ aggregate
- `wls`: T√≠nh k t·ªëi ∆∞u cho t·∫•t c·∫£ vintages c√πng l√∫c
- `wls_reg`: T√≠nh k t·ªëi ∆∞u v·ªõi regularization

### 2. Weight Mode

| Notebook | Weight Mode | Meaning |
|----------|-------------|---------|
| **Projection_done** | `equal` | M·ªçi vintage c√≥ weight = 1 |
| **Final_Workflow** | `ead` (default) | Weight theo EAD c·ªßa vintage |

**Impact**: ‚ö†Ô∏è HIGH
- `equal`: Vintage nh·ªè v√† l·ªõn c√≥ ·∫£nh h∆∞·ªüng nh∆∞ nhau
- `ead`: Vintage l·ªõn (nhi·ªÅu EAD) c√≥ ·∫£nh h∆∞·ªüng l·ªõn h∆°n

### 3. Regularization

| Notebook | Regularization | Lambda | K_Prior |
|----------|----------------|--------|---------|
| **Projection_done (v1)** | No | 0 | 0 |
| **Projection_done (v2)** | Yes | 1e-4 | 0.0 |
| **Final_Workflow** | No | 0 | 0 |

**Impact**: ‚ö†Ô∏è HIGH
- Regularization "shrinks" k v·ªÅ k_prior (0.0)
- Gi·∫£m overfitting
- K values nh·ªè h∆°n ‚Üí Conservative h∆°n

---

## üìê C√¥ng Th·ª©c Chi Ti·∫øt

### Method: ratio (Final_Workflow default)

```python
# Cho m·ªói vintage:
a = y_hat - y_vm    # Markov increment
d = y_tar - y_vm    # Actual increment

k_vintage = d / a   # Ratio per vintage
k_vintage = clip(k_vintage, 0, 1)  # Clip to [0, 1]

# Aggregate across vintages:
k_m = weighted_median(k_vintage, weights)
```

**∆Øu ƒëi·ªÉm**:
- ƒê∆°n gi·∫£n, d·ªÖ hi·ªÉu
- Robust v·ªõi outliers (d√πng median)

**Nh∆∞·ª£c ƒëi·ªÉm**:
- Kh√¥ng t·ªëi ∆∞u to√†n c·ª•c
- C√≥ th·ªÉ b·ªã ·∫£nh h∆∞·ªüng b·ªüi vintages c√≥ a nh·ªè

### Method: wls (Projection_done v1)

```python
# T·ªëi ∆∞u k cho t·∫•t c·∫£ vintages c√πng l√∫c:
k_m = Œ£(w_i ¬∑ a_i ¬∑ d_i) / Œ£(w_i ¬∑ a_i¬≤)

where:
  w_i = weight c·ªßa vintage i
  a_i = Markov increment c·ªßa vintage i
  d_i = Actual increment c·ªßa vintage i
```

**∆Øu ƒëi·ªÉm**:
- T·ªëi ∆∞u to√†n c·ª•c (minimize squared error)
- S·ª≠ d·ª•ng t·∫•t c·∫£ data hi·ªáu qu·∫£

**Nh∆∞·ª£c ƒëi·ªÉm**:
- C√≥ th·ªÉ overfit n·∫øu data √≠t
- Sensitive v·ªõi outliers

### Method: wls_reg (Projection_done v2)

```python
# Regularized WLS:
k_m = [Œ£(w_i ¬∑ a_i ¬∑ d_i) + Œª ¬∑ k_prior] / [Œ£(w_i ¬∑ a_i¬≤) + Œª]

where:
  Œª = lambda_k = 1e-4 (regularization strength)
  k_prior = 0.0 (prior value)
```

**∆Øu ƒëi·ªÉm**:
- Gi·∫£m overfitting
- Stable h∆°n v·ªõi data √≠t
- Bias k v·ªÅ k_prior (conservative)

**Nh∆∞·ª£c ƒëi·ªÉm**:
- C·∫ßn tune Œª
- C√≥ th·ªÉ underfit n·∫øu Œª qu√° l·ªõn

---

## üéØ ƒê·ªô Ch√≠nh X√°c: C√°i N√†o T·ªët H∆°n?

### Tr∆∞·ªùng H·ª£p 1: Data Nhi·ªÅu, Ch·∫•t L∆∞·ª£ng T·ªët

**Winner**: `wls` (Projection_done v1)

**L√Ω do**:
- T·ªëi ∆∞u to√†n c·ª•c
- S·ª≠ d·ª•ng t·∫•t c·∫£ data hi·ªáu qu·∫£
- Kh√¥ng b·ªã bias b·ªüi regularization

**Khi n√†o**: 
- C√≥ nhi·ªÅu vintages (>20)
- Data quality t·ªët
- √çt outliers

### Tr∆∞·ªùng H·ª£p 2: Data √çt, Noisy

**Winner**: `wls_reg` (Projection_done v2)

**L√Ω do**:
- Regularization gi·∫£m overfitting
- Stable h∆°n v·ªõi data √≠t
- Conservative (an to√†n h∆°n)

**Khi n√†o**:
- √çt vintages (<20)
- Data noisy
- C·∫ßn forecast conservative

### Tr∆∞·ªùng H·ª£p 3: Data C√≥ Outliers

**Winner**: `ratio` (Final_Workflow default)

**L√Ω do**:
- D√πng median ‚Üí Robust v·ªõi outliers
- Kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi extreme values

**Khi n√†o**:
- Data c√≥ outliers
- C·∫ßn robust estimation
- ƒê∆°n gi·∫£n, d·ªÖ explain

---

## üìä So S√°nh Th·ª±c T·∫ø

### V√≠ D·ª•: 3 Vintages

```
Vintage 1: a=0.05, d=0.06, w=100
Vintage 2: a=0.04, d=0.05, w=200
Vintage 3: a=0.10, d=0.08, w=50  (outlier)
```

#### Method: ratio
```python
k1 = 0.06/0.05 = 1.20 ‚Üí clip to 1.0
k2 = 0.05/0.04 = 1.25 ‚Üí clip to 1.0
k3 = 0.08/0.10 = 0.80

k_m = weighted_median([1.0, 1.0, 0.80], [100, 200, 50])
    = 1.0  (median)
```

#### Method: wls (equal weight)
```python
k_m = (1¬∑0.05¬∑0.06 + 1¬∑0.04¬∑0.05 + 1¬∑0.10¬∑0.08) / 
      (1¬∑0.05¬≤ + 1¬∑0.04¬≤ + 1¬∑0.10¬≤)
    = (0.003 + 0.002 + 0.008) / (0.0025 + 0.0016 + 0.01)
    = 0.013 / 0.0141
    = 0.92
```

#### Method: wls_reg (Œª=1e-4, k_prior=0)
```python
k_m = (0.013 + 1e-4¬∑0) / (0.0141 + 1e-4)
    = 0.013 / 0.0142
    = 0.916  (slightly lower than wls)
```

**K·∫øt qu·∫£**:
- `ratio`: 1.0 (robust, kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi outlier)
- `wls`: 0.92 (b·ªã k√©o xu·ªëng b·ªüi vintage 3)
- `wls_reg`: 0.916 (gi·ªØa wls v√† prior)

---

## üéØ Khuy·∫øn Ngh·ªã

### Cho Projection_done

**Hi·ªán t·∫°i**: D√πng c·∫£ 2 versions (wls v√† wls_reg)

**Khuy·∫øn ngh·ªã**: ‚úÖ **T·ªêT**

**L√Ω do**:
- So s√°nh ƒë∆∞·ª£c 2 approaches
- wls_reg conservative h∆°n cho long-term (36 months)
- C√≥ th·ªÉ ch·ªçn version ph√π h·ª£p v·ªõi risk appetite

**Best practice**:
```python
# Use wls_reg for final forecast (conservative)
forecast_results = forecast_all_vintages_partial_step(
    ...,
    k_by_mob=k_final_reg_by_mob,  # From wls_reg
)
```

### Cho Final_Workflow

**Hi·ªán t·∫°i**: D√πng `ratio` (default)

**Khuy·∫øn ngh·ªã**: ‚ö†Ô∏è **N√äN THAY ƒê·ªîI**

**L√Ω do**:
- `ratio` kh√¥ng t·ªëi ∆∞u cho short-term forecast
- `wls` t·ªët h∆°n khi c√≥ nhi·ªÅu data (19M rows)
- Kh√¥ng c·∫ßn regularization v√¨ data nhi·ªÅu

**Recommended change**:
```python
k_raw_by_mob, weight_by_mob, _ = fit_k_raw(
    actual_results=actual_results,
    matrices_by_mob=matrices_by_mob,
    parent_fallback=parent_fallback,
    states=BUCKETS_CANON,
    s30_states=BUCKETS_30P,
    include_co=True,
    denom_mode="disb",
    disb_total_by_vintage=disb_total_by_vintage,
    method="wls",              # ‚Üê ADD THIS
    weight_mode="equal",       # ‚Üê ADD THIS (or "ead")
    return_detail=True,
)
```

**Impact**:
- Forecast ch√≠nh x√°c h∆°n
- T·ªëi ∆∞u to√†n c·ª•c
- Consistent v·ªõi Projection_done approach

---

## üìä B·∫£ng T·ªïng H·ª£p

| Aspect | Projection_done | Final_Workflow | Winner |
|--------|-----------------|----------------|--------|
| **Method** | wls / wls_reg | ratio (default) | Projection_done |
| **Weight Mode** | equal | ead (default) | Depends |
| **Regularization** | Yes (v2) | No | Depends |
| **Optimization** | Global | Per-vintage | Projection_done |
| **Robustness** | Medium | High | Final_Workflow |
| **Accuracy (nhi·ªÅu data)** | High | Medium | Projection_done |
| **Accuracy (√≠t data)** | Medium (wls_reg: High) | Medium | wls_reg |
| **Simplicity** | Medium | High | Final_Workflow |

---

## üéì K·∫øt Lu·∫≠n

### ƒê·ªô Ch√≠nh X√°c

**V·ªõi data hi·ªán t·∫°i (19M rows, 130 segments)**:

1. **wls_reg** (Projection_done v2): ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
   - T·ªët nh·∫•t cho long-term
   - Conservative, stable
   - Gi·∫£m overfitting

2. **wls** (Projection_done v1): ‚≠ê‚≠ê‚≠ê‚≠ê
   - T·ªët cho short-term
   - T·ªëi ∆∞u to√†n c·ª•c
   - C·∫ßn data quality t·ªët

3. **ratio** (Final_Workflow): ‚≠ê‚≠ê‚≠ê
   - Robust v·ªõi outliers
   - ƒê∆°n gi·∫£n
   - Kh√¥ng t·ªëi ∆∞u to√†n c·ª•c

### Khuy·∫øn Ngh·ªã Cu·ªëi C√πng

#### Cho Final_Workflow
```python
# RECOMMENDED: Change to wls
method="wls",
weight_mode="equal",  # or "ead" if want to weight by size
```

#### Cho Projection_done
```python
# KEEP: wls_reg for conservative long-term forecast
method="wls_reg",
lambda_k=1e-4,
k_prior=0.0,
```

---

**Date**: 2026-01-17  
**Status**: ‚úÖ Analyzed  
**Recommendation**: Final_Workflow should use `wls` instead of `ratio`
